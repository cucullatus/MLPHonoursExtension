<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>mlp.layers</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
</script>
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="mlp-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="mlp-module.html">Package&nbsp;mlp</a> ::
        Module&nbsp;layers
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options">[<a href="javascript:void(0);" class="privatelink"
    onclick="toggle_private();">hide&nbsp;private</a>]</span></td></tr>
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="mlp.layers-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="mlp.layers-module.html">Module mlp.layers</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">  1</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">scipy</tt> <tt class="py-keyword">import</tt> <tt class="py-name">signal</tt> </tt>
<a name="L2"></a><tt class="py-lineno">  2</tt>  <tt class="py-line"><tt class="py-comment"># Machine Learning Practical (INFR11119),</tt> </tt>
<a name="L3"></a><tt class="py-lineno">  3</tt>  <tt class="py-line"><tt class="py-comment"># Pawel Swietojanski, University of Edinburgh</tt> </tt>
<a name="L4"></a><tt class="py-lineno">  4</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">sklearn</tt><tt class="py-op">.</tt><tt class="py-name">preprocessing</tt> <tt class="py-keyword">import</tt> <tt class="py-name">normalize</tt> </tt>
<a name="L5"></a><tt class="py-lineno">  5</tt>  <tt class="py-line"> </tt>
<a name="L6"></a><tt class="py-lineno">  6</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">numpy</tt> </tt>
<a name="L7"></a><tt class="py-lineno">  7</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">logging</tt> </tt>
<a name="L8"></a><tt class="py-lineno">  8</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-0" class="py-name" targets="Package mlp=mlp-module.html"><a title="mlp" class="py-name" href="#" onclick="return doclink('link-0', 'mlp', 'link-0');">mlp</a></tt><tt class="py-op">.</tt><tt id="link-1" class="py-name" targets="Module mlp.costs=mlp.costs-module.html"><a title="mlp.costs" class="py-name" href="#" onclick="return doclink('link-1', 'costs', 'link-1');">costs</a></tt> <tt class="py-keyword">import</tt> <tt id="link-2" class="py-name" targets="Class mlp.costs.Cost=mlp.costs.Cost-class.html"><a title="mlp.costs.Cost" class="py-name" href="#" onclick="return doclink('link-2', 'Cost', 'link-2');">Cost</a></tt> </tt>
<a name="L9"></a><tt class="py-lineno">  9</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">matplotlib</tt><tt class="py-op">.</tt><tt class="py-name">pyplot</tt> <tt class="py-keyword">as</tt> <tt class="py-name">plt</tt> </tt>
<a name="L10"></a><tt class="py-lineno"> 10</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">scipy</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt> <tt class="py-keyword">import</tt> <tt class="py-name">dft</tt> </tt>
<a name="L11"></a><tt class="py-lineno"> 11</tt>  <tt class="py-line"> </tt>
<a name="L12"></a><tt class="py-lineno"> 12</tt>  <tt class="py-line"> </tt>
<a name="L13"></a><tt class="py-lineno"> 13</tt>  <tt class="py-line"><tt id="link-3" class="py-name" targets="Variable mlp.convlin.logger=mlp.convlin-module.html#logger,Variable mlp.dataset.logger=mlp.dataset-module.html#logger,Variable mlp.layers.logger=mlp.layers-module.html#logger,Variable mlp.optimisers.logger=mlp.optimisers-module.html#logger"><a title="mlp.convlin.logger
mlp.dataset.logger
mlp.layers.logger
mlp.optimisers.logger" class="py-name" href="#" onclick="return doclink('link-3', 'logger', 'link-3');">logger</a></tt> <tt class="py-op">=</tt> <tt class="py-name">logging</tt><tt class="py-op">.</tt><tt class="py-name">getLogger</tt><tt class="py-op">(</tt><tt class="py-name">__name__</tt><tt class="py-op">)</tt> </tt>
<a name="L14"></a><tt class="py-lineno"> 14</tt>  <tt class="py-line"> </tt>
<a name="L15"></a><tt class="py-lineno"> 15</tt>  <tt class="py-line"> </tt>
<a name="max_and_argmax"></a><div id="max_and_argmax-def"><a name="L16"></a><tt class="py-lineno"> 16</tt> <a class="py-toggle" href="#" id="max_and_argmax-toggle" onclick="return toggle('max_and_argmax');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers-module.html#max_and_argmax">max_and_argmax</a><tt class="py-op">(</tt><tt class="py-param">x</tt><tt class="py-op">,</tt> <tt class="py-param">axes</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">keepdims_max</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-param">keepdims_argmax</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="max_and_argmax-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="max_and_argmax-expanded"><a name="L17"></a><tt class="py-lineno"> 17</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L18"></a><tt class="py-lineno"> 18</tt>  <tt class="py-line"><tt class="py-docstring">    Return both max and argmax for the given multi-dimensional array, possibly</tt> </tt>
<a name="L19"></a><tt class="py-lineno"> 19</tt>  <tt class="py-line"><tt class="py-docstring">    preserve the original shapes</tt> </tt>
<a name="L20"></a><tt class="py-lineno"> 20</tt>  <tt class="py-line"><tt class="py-docstring">    :param x: input tensor</tt> </tt>
<a name="L21"></a><tt class="py-lineno"> 21</tt>  <tt class="py-line"><tt class="py-docstring">    :param axes: tuple of ints denoting axes across which</tt> </tt>
<a name="L22"></a><tt class="py-lineno"> 22</tt>  <tt class="py-line"><tt class="py-docstring">                 one should perform reduction</tt> </tt>
<a name="L23"></a><tt class="py-lineno"> 23</tt>  <tt class="py-line"><tt class="py-docstring">    :param keepdims_max: boolean, if true, shape of x is preserved in result</tt> </tt>
<a name="L24"></a><tt class="py-lineno"> 24</tt>  <tt class="py-line"><tt class="py-docstring">    :param keepdims_argmax:, boolean, if true, shape of x is preserved in result</tt> </tt>
<a name="L25"></a><tt class="py-lineno"> 25</tt>  <tt class="py-line"><tt class="py-docstring">    :return: max (number) and argmax (indices) of max element along certain axes</tt> </tt>
<a name="L26"></a><tt class="py-lineno"> 26</tt>  <tt class="py-line"><tt class="py-docstring">             in multi-dimensional tensor</tt> </tt>
<a name="L27"></a><tt class="py-lineno"> 27</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L28"></a><tt class="py-lineno"> 28</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">axes</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L29"></a><tt class="py-lineno"> 29</tt>  <tt class="py-line">        <tt class="py-name">rval_argmax</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">argmax</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt> </tt>
<a name="L30"></a><tt class="py-lineno"> 30</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">keepdims_argmax</tt><tt class="py-op">:</tt> </tt>
<a name="L31"></a><tt class="py-lineno"> 31</tt>  <tt class="py-line">            <tt class="py-name">rval_argmax</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">unravel_index</tt><tt class="py-op">(</tt><tt class="py-name">rval_argmax</tt><tt class="py-op">,</tt> <tt class="py-name">x</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt> </tt>
<a name="L32"></a><tt class="py-lineno"> 32</tt>  <tt class="py-line">    <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L33"></a><tt class="py-lineno"> 33</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">axes</tt><tt class="py-op">,</tt> <tt class="py-name">int</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L34"></a><tt class="py-lineno"> 34</tt>  <tt class="py-line">            <tt class="py-name">axes</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-name">axes</tt><tt class="py-op">,</tt><tt class="py-op">)</tt> </tt>
<a name="L35"></a><tt class="py-lineno"> 35</tt>  <tt class="py-line">        <tt class="py-name">axes</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">axes</tt><tt class="py-op">)</tt> </tt>
<a name="L36"></a><tt class="py-lineno"> 36</tt>  <tt class="py-line">        <tt class="py-name">keep_axes</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-name">i</tt> <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">range</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt><tt class="py-op">)</tt> <tt class="py-keyword">if</tt> <tt class="py-name">i</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt class="py-name">axes</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L37"></a><tt class="py-lineno"> 37</tt>  <tt class="py-line">        <tt class="py-name">transposed_x</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">transpose</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">concatenate</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">keep_axes</tt><tt class="py-op">,</tt> <tt class="py-name">axes</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L38"></a><tt class="py-lineno"> 38</tt>  <tt class="py-line">        <tt class="py-name">reshaped_x</tt> <tt class="py-op">=</tt> <tt class="py-name">transposed_x</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt> </tt>
<a name="L39"></a><tt class="py-lineno"> 39</tt>  <tt class="py-line">            <tt class="py-name">transposed_x</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">keep_axes</tt><tt class="py-op">)</tt><tt class="py-op">]</tt> <tt class="py-op">+</tt> <tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L40"></a><tt class="py-lineno"> 40</tt>  <tt class="py-line">        <tt class="py-name">rval_argmax</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">asarray</tt><tt class="py-op">(</tt> </tt>
<a name="L41"></a><tt class="py-lineno"> 41</tt>  <tt class="py-line">            <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">argmax</tt><tt class="py-op">(</tt><tt class="py-name">reshaped_x</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">dtype</tt><tt class="py-op">=</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">int64</tt><tt class="py-op">)</tt> </tt>
<a name="L42"></a><tt class="py-lineno"> 42</tt>  <tt class="py-line"> </tt>
<a name="L43"></a><tt class="py-lineno"> 43</tt>  <tt class="py-line">        <tt class="py-comment"># rval_max_arg keeps the arg index referencing to the axis along which reduction was performed (axis=-1)</tt> </tt>
<a name="L44"></a><tt class="py-lineno"> 44</tt>  <tt class="py-line">        <tt class="py-comment"># when keepdims_argmax is True we need to map it back to the original shape of tensor x</tt> </tt>
<a name="L45"></a><tt class="py-lineno"> 45</tt>  <tt class="py-line">        <tt class="py-comment"># print 'rval maxaarg', rval_argmax.ndim, rval_argmax.shape,</tt> </tt>
<a name="L46"></a><tt class="py-lineno"> 46</tt>  <tt class="py-line">        <tt class="py-comment"># rval_argmax</tt> </tt>
<a name="L47"></a><tt class="py-lineno"> 47</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">keepdims_argmax</tt><tt class="py-op">:</tt> </tt>
<a name="L48"></a><tt class="py-lineno"> 48</tt>  <tt class="py-line">            <tt class="py-name">dim</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-name">x</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-name">a</tt><tt class="py-op">]</tt> <tt class="py-keyword">for</tt> <tt class="py-name">a</tt> <tt class="py-keyword">in</tt> <tt class="py-name">axes</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L49"></a><tt class="py-lineno"> 49</tt>  <tt class="py-line">            <tt class="py-name">rval_argmax</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-name">idx</tt> <tt class="py-op">+</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">unravel_index</tt><tt class="py-op">(</tt><tt class="py-name">val</tt><tt class="py-op">,</tt> <tt class="py-name">dim</tt><tt class="py-op">)</tt> </tt>
<a name="L50"></a><tt class="py-lineno"> 50</tt>  <tt class="py-line">                                       <tt class="py-keyword">for</tt> <tt class="py-name">idx</tt><tt class="py-op">,</tt> <tt class="py-name">val</tt> <tt class="py-keyword">in</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">ndenumerate</tt><tt class="py-op">(</tt><tt class="py-name">rval_argmax</tt><tt class="py-op">)</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L51"></a><tt class="py-lineno"> 51</tt>  <tt class="py-line">            <tt class="py-comment"># convert to numpy indexing convention (row indices first, then</tt> </tt>
<a name="L52"></a><tt class="py-lineno"> 52</tt>  <tt class="py-line">            <tt class="py-comment"># columns)</tt> </tt>
<a name="L53"></a><tt class="py-lineno"> 53</tt>  <tt class="py-line">            <tt class="py-name">rval_argmax</tt> <tt class="py-op">=</tt> <tt class="py-name">zip</tt><tt class="py-op">(</tt><tt class="py-op">*</tt><tt class="py-name">rval_argmax</tt><tt class="py-op">)</tt> </tt>
<a name="L54"></a><tt class="py-lineno"> 54</tt>  <tt class="py-line"> </tt>
<a name="L55"></a><tt class="py-lineno"> 55</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">keepdims_max</tt> <tt class="py-keyword">is</tt> <tt class="py-name">False</tt> <tt class="py-keyword">and</tt> <tt class="py-name">keepdims_argmax</tt> <tt class="py-keyword">is</tt> <tt class="py-name">True</tt><tt class="py-op">:</tt> </tt>
<a name="L56"></a><tt class="py-lineno"> 56</tt>  <tt class="py-line">        <tt class="py-comment"># this could potentially save O(N) steps by not traversing array once more</tt> </tt>
<a name="L57"></a><tt class="py-lineno"> 57</tt>  <tt class="py-line">        <tt class="py-comment"># to get max value, haven't benchmark it though</tt> </tt>
<a name="L58"></a><tt class="py-lineno"> 58</tt>  <tt class="py-line">        <tt class="py-name">rval_max</tt> <tt class="py-op">=</tt> <tt class="py-name">x</tt><tt class="py-op">[</tt><tt class="py-name">rval_argmax</tt><tt class="py-op">]</tt> </tt>
<a name="L59"></a><tt class="py-lineno"> 59</tt>  <tt class="py-line">    <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L60"></a><tt class="py-lineno"> 60</tt>  <tt class="py-line">        <tt class="py-name">rval_max</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">asarray</tt><tt class="py-op">(</tt> </tt>
<a name="L61"></a><tt class="py-lineno"> 61</tt>  <tt class="py-line">            <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">amax</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-name">axes</tt><tt class="py-op">,</tt> <tt class="py-name">keepdims</tt><tt class="py-op">=</tt><tt class="py-name">keepdims_max</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L62"></a><tt class="py-lineno"> 62</tt>  <tt class="py-line"> </tt>
<a name="L63"></a><tt class="py-lineno"> 63</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">rval_max</tt><tt class="py-op">,</tt> <tt class="py-name">rval_argmax</tt> </tt>
</div><a name="L64"></a><tt class="py-lineno"> 64</tt>  <tt class="py-line"> </tt>
<a name="L65"></a><tt class="py-lineno"> 65</tt>  <tt class="py-line"> </tt>
<a name="MLP"></a><div id="MLP-def"><a name="L66"></a><tt class="py-lineno"> 66</tt> <a class="py-toggle" href="#" id="MLP-toggle" onclick="return toggle('MLP');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html">MLP</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="MLP-expanded"><a name="L67"></a><tt class="py-lineno"> 67</tt>  <tt class="py-line"> </tt>
<a name="L68"></a><tt class="py-lineno"> 68</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L69"></a><tt class="py-lineno"> 69</tt>  <tt class="py-line"><tt class="py-docstring">    This is a container for an arbitrary sequence of other transforms</tt> </tt>
<a name="L70"></a><tt class="py-lineno"> 70</tt>  <tt class="py-line"><tt class="py-docstring">    On top of this, the class also keeps the state of the model, i.e.</tt> </tt>
<a name="L71"></a><tt class="py-lineno"> 71</tt>  <tt class="py-line"><tt class="py-docstring">    the result of forward (activations) and backward (deltas) passes</tt> </tt>
<a name="L72"></a><tt class="py-lineno"> 72</tt>  <tt class="py-line"><tt class="py-docstring">    through the model (for a mini-batch), which is required to compute</tt> </tt>
<a name="L73"></a><tt class="py-lineno"> 73</tt>  <tt class="py-line"><tt class="py-docstring">    the gradients for the parameters</tt> </tt>
<a name="L74"></a><tt class="py-lineno"> 74</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L75"></a><tt class="py-lineno"> 75</tt>  <tt class="py-line"> </tt>
<a name="MLP.__init__"></a><div id="MLP.__init__-def"><a name="L76"></a><tt class="py-lineno"> 76</tt> <a class="py-toggle" href="#" id="MLP.__init__-toggle" onclick="return toggle('MLP.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">,</tt> <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.__init__-expanded"><a name="L77"></a><tt class="py-lineno"> 77</tt>  <tt class="py-line"> </tt>
<a name="L78"></a><tt class="py-lineno"> 78</tt>  <tt class="py-line">        <tt class="py-keyword">assert</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt id="link-4" class="py-name" targets="Method mlp.costs.CECost.cost()=mlp.costs.CECost-class.html#cost,Method mlp.costs.Cost.cost()=mlp.costs.Cost-class.html#cost,Method mlp.costs.MSECost.cost()=mlp.costs.MSECost-class.html#cost"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-4', 'cost', 'link-4');">cost</a></tt><tt class="py-op">,</tt> <tt id="link-5" class="py-name"><a title="mlp.costs.Cost" class="py-name" href="#" onclick="return doclink('link-5', 'Cost', 'link-2');">Cost</a></tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt> </tt>
<a name="L79"></a><tt class="py-lineno"> 79</tt>  <tt class="py-line">            <tt class="py-string">"Cost needs to be of type mlp.costs.Cost, got %s"</tt> <tt class="py-op">%</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt id="link-6" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-6', 'cost', 'link-4');">cost</a></tt><tt class="py-op">)</tt> </tt>
<a name="L80"></a><tt class="py-lineno"> 80</tt>  <tt class="py-line">        <tt class="py-op">)</tt> </tt>
<a name="L81"></a><tt class="py-lineno"> 81</tt>  <tt class="py-line"> </tt>
<a name="L82"></a><tt class="py-lineno"> 82</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-7" class="py-name" targets="Module mlp.layers=mlp.layers-module.html"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-7', 'layers', 'link-7');">layers</a></tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt>  <tt class="py-comment"># the actual list of network layers</tt> </tt>
<a name="L83"></a><tt class="py-lineno"> 83</tt>  <tt class="py-line">        <tt class="py-comment"># keeps forward-pass activations (h from equations)</tt> </tt>
<a name="L84"></a><tt class="py-lineno"> 84</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L85"></a><tt class="py-lineno"> 85</tt>  <tt class="py-line">        <tt class="py-comment"># for a given minibatch (or features at 0th index)</tt> </tt>
<a name="L86"></a><tt class="py-lineno"> 86</tt>  <tt class="py-line">        <tt class="py-comment"># keeps back-propagated error signals (deltas from equations)</tt> </tt>
<a name="L87"></a><tt class="py-lineno"> 87</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">deltas</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L88"></a><tt class="py-lineno"> 88</tt>  <tt class="py-line">        <tt class="py-comment"># for a given minibatch and each layer</tt> </tt>
<a name="L89"></a><tt class="py-lineno"> 89</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-8" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-8', 'cost', 'link-4');">cost</a></tt> <tt class="py-op">=</tt> <tt id="link-9" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-9', 'cost', 'link-4');">cost</a></tt> </tt>
<a name="L90"></a><tt class="py-lineno"> 90</tt>  <tt class="py-line"> </tt>
<a name="L91"></a><tt class="py-lineno"> 91</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rng</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L92"></a><tt class="py-lineno"> 92</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">random</tt><tt class="py-op">.</tt><tt class="py-name">RandomState</tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-number">2015</tt><tt class="py-op">,</tt> <tt class="py-number">11</tt><tt class="py-op">,</tt> <tt class="py-number">11</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L93"></a><tt class="py-lineno"> 93</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L94"></a><tt class="py-lineno"> 94</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt> <tt class="py-op">=</tt> <tt class="py-name">rng</tt> </tt>
</div><a name="L95"></a><tt class="py-lineno"> 95</tt>  <tt class="py-line">            <tt class="py-comment"># print "rng inherited"</tt> </tt>
<a name="L96"></a><tt class="py-lineno"> 96</tt>  <tt class="py-line"> </tt>
<a name="MLP.fprop"></a><div id="MLP.fprop-def"><a name="L97"></a><tt class="py-lineno"> 97</tt> <a class="py-toggle" href="#" id="MLP.fprop-toggle" onclick="return toggle('MLP.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">,</tt> <tt class="py-param">noise_up_layer</tt><tt class="py-op">=</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-param">noise_list</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">wrong</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.fprop-expanded"><a name="L98"></a><tt class="py-lineno"> 98</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L99"></a><tt class="py-lineno"> 99</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L100"></a><tt class="py-lineno">100</tt>  <tt class="py-line"><tt class="py-docstring">        :param inputs: mini-batch of data-points x</tt> </tt>
<a name="L101"></a><tt class="py-lineno">101</tt>  <tt class="py-line"><tt class="py-docstring">        :return: y (top layer activation) which is an estimate of y given x</tt> </tt>
<a name="L102"></a><tt class="py-lineno">102</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L103"></a><tt class="py-lineno">103</tt>  <tt class="py-line"> </tt>
<a name="L104"></a><tt class="py-lineno">104</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">)</tt> <tt class="py-op">!=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-10" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-10', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L105"></a><tt class="py-lineno">105</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">None</tt><tt class="py-op">]</tt><tt class="py-op">*</tt><tt class="py-op">(</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-11" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-11', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L106"></a><tt class="py-lineno">106</tt>  <tt class="py-line"> </tt>
<a name="L107"></a><tt class="py-lineno">107</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">x</tt> </tt>
<a name="L108"></a><tt class="py-lineno">108</tt>  <tt class="py-line">        <tt class="py-comment"># print "layers: &gt;&gt;&gt;&gt;" + str(len(self.activations))</tt> </tt>
<a name="L109"></a><tt class="py-lineno">109</tt>  <tt class="py-line">        <tt class="py-comment"># print "layer len: ", len(self.layers)</tt> </tt>
<a name="L110"></a><tt class="py-lineno">110</tt>  <tt class="py-line">        <tt class="py-comment"># if noise_list is not None:</tt> </tt>
<a name="L111"></a><tt class="py-lineno">111</tt>  <tt class="py-line">        <tt class="py-comment">#     print "noise stack len: ", len(noise_list)</tt> </tt>
<a name="L112"></a><tt class="py-lineno">112</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">xrange</tt><tt class="py-op">(</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-12" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-12', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L113"></a><tt class="py-lineno">113</tt>  <tt class="py-line">            <tt class="py-comment"># print "layer : " + str(i)</tt> </tt>
<a name="L114"></a><tt class="py-lineno">114</tt>  <tt class="py-line">            <tt class="py-comment"># print "odim : " + str(self.layers[i].odim)</tt> </tt>
<a name="L115"></a><tt class="py-lineno">115</tt>  <tt class="py-line">            <tt class="py-comment"># print "idim : " + str(self.layers[i].idim)</tt> </tt>
<a name="L116"></a><tt class="py-lineno">116</tt>  <tt class="py-line">            <tt class="py-comment"># print "activation : " + str(self.activations[i].shape)</tt> </tt>
<a name="L117"></a><tt class="py-lineno">117</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-13" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-13', 'layers', 'link-7');">layers</a></tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-14" class="py-name" targets="Method mlp.convlin.ConvLinear_Opt.fprop()=mlp.convlin.ConvLinear_Opt-class.html#fprop,Method mlp.convlin.ConvMaxPool2D.fprop()=mlp.convlin.ConvMaxPool2D-class.html#fprop,Method mlp.convlin.ConvRelu_Opt.fprop()=mlp.convlin.ConvRelu_Opt-class.html#fprop,Method mlp.convlin.ConvSigmoid_Opt.fprop()=mlp.convlin.ConvSigmoid_Opt-class.html#fprop,Method mlp.layers.ComplexAbs.fprop()=mlp.layers.ComplexAbs-class.html#fprop,Method mlp.layers.ComplexLinear.fprop()=mlp.layers.ComplexLinear-class.html#fprop,Method mlp.layers.Layer.fprop()=mlp.layers.Layer-class.html#fprop,Method mlp.layers.Linear.fprop()=mlp.layers.Linear-class.html#fprop,Method mlp.layers.MLP.fprop()=mlp.layers.MLP-class.html#fprop,Method mlp.layers.Maxout.fprop()=mlp.layers.Maxout-class.html#fprop,Method mlp.layers.Relu.fprop()=mlp.layers.Relu-class.html#fprop,Method mlp.layers.Sigmoid.fprop()=mlp.layers.Sigmoid-class.html#fprop,Method mlp.layers.Softmax.fprop()=mlp.layers.Softmax-class.html#fprop,Method mlp.layers.Tanh.fprop()=mlp.layers.Tanh-class.html#fprop"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-14', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L118"></a><tt class="py-lineno">118</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">noise_up_layer</tt> <tt class="py-op">!=</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt> <tt class="py-keyword">and</tt> <tt class="py-name">i</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-15" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-15', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L119"></a><tt class="py-lineno">119</tt>  <tt class="py-line">                <tt class="py-comment"># print "Layer: ", i</tt> </tt>
<a name="L120"></a><tt class="py-lineno">120</tt>  <tt class="py-line">                <tt class="py-comment"># nomn pythonic hack prepare your ...</tt> </tt>
<a name="L121"></a><tt class="py-lineno">121</tt>  <tt class="py-line">                <tt class="py-comment"># this is moribidly obese</tt> </tt>
<a name="L122"></a><tt class="py-lineno">122</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-name">wrong</tt><tt class="py-op">:</tt> </tt>
<a name="L123"></a><tt class="py-lineno">123</tt>  <tt class="py-line">                    <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-op">*=</tt> <tt class="py-name">noise_list</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt> </tt>
<a name="L124"></a><tt class="py-lineno">124</tt>  <tt class="py-line">                <tt class="py-comment"># pass</tt> </tt>
<a name="L125"></a><tt class="py-lineno">125</tt>  <tt class="py-line"> </tt>
<a name="L126"></a><tt class="py-lineno">126</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
</div><a name="L127"></a><tt class="py-lineno">127</tt>  <tt class="py-line"> </tt>
<a name="MLP.fprop_dropout"></a><div id="MLP.fprop_dropout-def"><a name="L128"></a><tt class="py-lineno">128</tt> <a class="py-toggle" href="#" id="MLP.fprop_dropout-toggle" onclick="return toggle('MLP.fprop_dropout');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#fprop_dropout">fprop_dropout</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">,</tt> <tt class="py-param">dp_scheduler</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.fprop_dropout-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.fprop_dropout-expanded"><a name="L129"></a><tt class="py-lineno">129</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L130"></a><tt class="py-lineno">130</tt>  <tt class="py-line"><tt class="py-docstring">        :param inputs: mini-batch of data-points x</tt> </tt>
<a name="L131"></a><tt class="py-lineno">131</tt>  <tt class="py-line"><tt class="py-docstring">        :param dp_scheduler: dropout scheduler</tt> </tt>
<a name="L132"></a><tt class="py-lineno">132</tt>  <tt class="py-line"><tt class="py-docstring">        :return: y (top layer activation) which is an estimate of y given x</tt> </tt>
<a name="L133"></a><tt class="py-lineno">133</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L134"></a><tt class="py-lineno">134</tt>  <tt class="py-line"> </tt>
<a name="L135"></a><tt class="py-lineno">135</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">)</tt> <tt class="py-op">!=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-16" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-16', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L136"></a><tt class="py-lineno">136</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">None</tt><tt class="py-op">]</tt><tt class="py-op">*</tt><tt class="py-op">(</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-17" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-17', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L137"></a><tt class="py-lineno">137</tt>  <tt class="py-line"> </tt>
<a name="L138"></a><tt class="py-lineno">138</tt>  <tt class="py-line">        <tt class="py-name">p_inp</tt><tt class="py-op">,</tt> <tt class="py-name">p_hid</tt> <tt class="py-op">=</tt> <tt class="py-name">dp_scheduler</tt><tt class="py-op">.</tt><tt id="link-18" class="py-name" targets="Method mlp.schedulers.DropoutFixed.get_rate()=mlp.schedulers.DropoutFixed-class.html#get_rate,Method mlp.schedulers.LearningRateFixed.get_rate()=mlp.schedulers.LearningRateFixed-class.html#get_rate,Method mlp.schedulers.LearningRateList.get_rate()=mlp.schedulers.LearningRateList-class.html#get_rate,Method mlp.schedulers.LearningRateNewBob.get_rate()=mlp.schedulers.LearningRateNewBob-class.html#get_rate,Method mlp.schedulers.LearningRateScheduler.get_rate()=mlp.schedulers.LearningRateScheduler-class.html#get_rate"><a title="mlp.schedulers.DropoutFixed.get_rate
mlp.schedulers.LearningRateFixed.get_rate
mlp.schedulers.LearningRateList.get_rate
mlp.schedulers.LearningRateNewBob.get_rate
mlp.schedulers.LearningRateScheduler.get_rate" class="py-name" href="#" onclick="return doclink('link-18', 'get_rate', 'link-18');">get_rate</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L139"></a><tt class="py-lineno">139</tt>  <tt class="py-line"> </tt>
<a name="L140"></a><tt class="py-lineno">140</tt>  <tt class="py-line">        <tt class="py-name">d_inp</tt> <tt class="py-op">=</tt> <tt class="py-number">1</tt> </tt>
<a name="L141"></a><tt class="py-lineno">141</tt>  <tt class="py-line">        <tt class="py-name">p_inp_scaler</tt><tt class="py-op">,</tt> <tt class="py-name">p_hid_scaler</tt> <tt class="py-op">=</tt> <tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-name">p_inp</tt><tt class="py-op">,</tt> <tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-name">p_hid</tt> </tt>
<a name="L142"></a><tt class="py-lineno">142</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">p_inp</tt> <tt class="py-op">&lt;</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L143"></a><tt class="py-lineno">143</tt>  <tt class="py-line">            <tt class="py-name">d_inp</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt><tt class="py-op">.</tt><tt class="py-name">binomial</tt><tt class="py-op">(</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">p_inp</tt><tt class="py-op">,</tt> <tt class="py-name">size</tt><tt class="py-op">=</tt><tt class="py-name">x</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt> </tt>
<a name="L144"></a><tt class="py-lineno">144</tt>  <tt class="py-line"> </tt>
<a name="L145"></a><tt class="py-lineno">145</tt>  <tt class="py-line">        <tt class="py-comment"># it's OK to scale the inputs by p_inp_scaler here</tt> </tt>
<a name="L146"></a><tt class="py-lineno">146</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">p_inp_scaler</tt><tt class="py-op">*</tt><tt class="py-name">d_inp</tt><tt class="py-op">*</tt><tt class="py-name">x</tt> </tt>
<a name="L147"></a><tt class="py-lineno">147</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-19" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-19', 'layers', 'link-7');">layers</a></tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-20" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-20', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L148"></a><tt class="py-lineno">148</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">xrange</tt><tt class="py-op">(</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-21" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-21', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L149"></a><tt class="py-lineno">149</tt>  <tt class="py-line">            <tt class="py-name">d_hid</tt> <tt class="py-op">=</tt> <tt class="py-number">1</tt> </tt>
<a name="L150"></a><tt class="py-lineno">150</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">p_hid</tt> <tt class="py-op">&lt;</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L151"></a><tt class="py-lineno">151</tt>  <tt class="py-line">                <tt class="py-name">d_hid</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt><tt class="py-op">.</tt><tt class="py-name">binomial</tt><tt class="py-op">(</tt> </tt>
<a name="L152"></a><tt class="py-lineno">152</tt>  <tt class="py-line">                    <tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">p_hid</tt><tt class="py-op">,</tt> <tt class="py-name">size</tt><tt class="py-op">=</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt> </tt>
<a name="L153"></a><tt class="py-lineno">153</tt>  <tt class="py-line">            <tt class="py-comment"># but not the hidden activations, since the non-linearity grad</tt> </tt>
<a name="L154"></a><tt class="py-lineno">154</tt>  <tt class="py-line">            <tt class="py-comment"># *may* explicitly depend on them</tt> </tt>
<a name="L155"></a><tt class="py-lineno">155</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt> <tt class="py-op">*=</tt> <tt class="py-name">d_hid</tt> </tt>
<a name="L156"></a><tt class="py-lineno">156</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt> </tt>
<a name="L157"></a><tt class="py-lineno">157</tt>  <tt class="py-line">                <tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-22" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-22', 'layers', 'link-7');">layers</a></tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-23" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-23', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">p_hid_scaler</tt><tt class="py-op">*</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L158"></a><tt class="py-lineno">158</tt>  <tt class="py-line"> </tt>
<a name="L159"></a><tt class="py-lineno">159</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
</div><a name="L160"></a><tt class="py-lineno">160</tt>  <tt class="py-line"> </tt>
<a name="MLP.bprop"></a><div id="MLP.bprop-def"><a name="L161"></a><tt class="py-lineno">161</tt> <a class="py-toggle" href="#" id="MLP.bprop-toggle" onclick="return toggle('MLP.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">cost_grad</tt><tt class="py-op">,</tt> <tt class="py-param">dp_scheduler</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.bprop-expanded"><a name="L162"></a><tt class="py-lineno">162</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L163"></a><tt class="py-lineno">163</tt>  <tt class="py-line"><tt class="py-docstring">        :param cost_grad: matrix -- grad of the cost w.r.t y</tt> </tt>
<a name="L164"></a><tt class="py-lineno">164</tt>  <tt class="py-line"><tt class="py-docstring">        :return: None, the deltas are kept in the model</tt> </tt>
<a name="L165"></a><tt class="py-lineno">165</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L166"></a><tt class="py-lineno">166</tt>  <tt class="py-line"> </tt>
<a name="L167"></a><tt class="py-lineno">167</tt>  <tt class="py-line">        <tt class="py-comment"># allocate the list of deltas for each layer</tt> </tt>
<a name="L168"></a><tt class="py-lineno">168</tt>  <tt class="py-line">        <tt class="py-comment"># note, we do not use all of those fields but</tt> </tt>
<a name="L169"></a><tt class="py-lineno">169</tt>  <tt class="py-line">        <tt class="py-comment"># want to keep it aligned 1:1 with activations,</tt> </tt>
<a name="L170"></a><tt class="py-lineno">170</tt>  <tt class="py-line">        <tt class="py-comment"># which will simplify indexing later on when</tt> </tt>
<a name="L171"></a><tt class="py-lineno">171</tt>  <tt class="py-line">        <tt class="py-comment"># computing grads w.r.t parameters</tt> </tt>
<a name="L172"></a><tt class="py-lineno">172</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">deltas</tt><tt class="py-op">)</tt> <tt class="py-op">!=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L173"></a><tt class="py-lineno">173</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">deltas</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">None</tt><tt class="py-op">]</tt><tt class="py-op">*</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">)</tt> </tt>
<a name="L174"></a><tt class="py-lineno">174</tt>  <tt class="py-line"> </tt>
<a name="L175"></a><tt class="py-lineno">175</tt>  <tt class="py-line">        <tt class="py-comment"># treat the top layer in special way, as it deals with the</tt> </tt>
<a name="L176"></a><tt class="py-lineno">176</tt>  <tt class="py-line">        <tt class="py-comment"># cost, which may lead to some simplifications</tt> </tt>
<a name="L177"></a><tt class="py-lineno">177</tt>  <tt class="py-line">        <tt class="py-name">top_layer_idx</tt> <tt class="py-op">=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-24" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-24', 'layers', 'link-7');">layers</a></tt><tt class="py-op">)</tt> </tt>
<a name="L178"></a><tt class="py-lineno">178</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">deltas</tt><tt class="py-op">[</tt><tt class="py-name">top_layer_idx</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-25" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-25', 'layers', 'link-7');">layers</a></tt><tt class="py-op">[</tt><tt class="py-name">top_layer_idx</tt> <tt class="py-op">-</tt> <tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">.</tt>\ </tt>
<a name="L179"></a><tt class="py-lineno">179</tt>  <tt class="py-line">            <tt id="link-26" class="py-name" targets="Method mlp.convlin.ConvLinear_Opt.bprop_cost()=mlp.convlin.ConvLinear_Opt-class.html#bprop_cost,Method mlp.convlin.ConvRelu_Opt.bprop_cost()=mlp.convlin.ConvRelu_Opt-class.html#bprop_cost,Method mlp.convlin.ConvSigmoid_Opt.bprop_cost()=mlp.convlin.ConvSigmoid_Opt-class.html#bprop_cost,Method mlp.layers.ComplexAbs.bprop_cost()=mlp.layers.ComplexAbs-class.html#bprop_cost,Method mlp.layers.ComplexLinear.bprop_cost()=mlp.layers.ComplexLinear-class.html#bprop_cost,Method mlp.layers.Layer.bprop_cost()=mlp.layers.Layer-class.html#bprop_cost,Method mlp.layers.Linear.bprop_cost()=mlp.layers.Linear-class.html#bprop_cost,Method mlp.layers.Maxout.bprop_cost()=mlp.layers.Maxout-class.html#bprop_cost,Method mlp.layers.Relu.bprop_cost()=mlp.layers.Relu-class.html#bprop_cost,Method mlp.layers.Sigmoid.bprop_cost()=mlp.layers.Sigmoid-class.html#bprop_cost,Method mlp.layers.Softmax.bprop_cost()=mlp.layers.Softmax-class.html#bprop_cost,Method mlp.layers.Tanh.bprop_cost()=mlp.layers.Tanh-class.html#bprop_cost"><a title="mlp.convlin.ConvLinear_Opt.bprop_cost
mlp.convlin.ConvRelu_Opt.bprop_cost
mlp.convlin.ConvSigmoid_Opt.bprop_cost
mlp.layers.ComplexAbs.bprop_cost
mlp.layers.ComplexLinear.bprop_cost
mlp.layers.Layer.bprop_cost
mlp.layers.Linear.bprop_cost
mlp.layers.Maxout.bprop_cost
mlp.layers.Relu.bprop_cost
mlp.layers.Sigmoid.bprop_cost
mlp.layers.Softmax.bprop_cost
mlp.layers.Tanh.bprop_cost" class="py-name" href="#" onclick="return doclink('link-26', 'bprop_cost', 'link-26');">bprop_cost</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">top_layer_idx</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">cost_grad</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-27" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-27', 'cost', 'link-4');">cost</a></tt><tt class="py-op">)</tt> </tt>
<a name="L180"></a><tt class="py-lineno">180</tt>  <tt class="py-line"> </tt>
<a name="L181"></a><tt class="py-lineno">181</tt>  <tt class="py-line"> </tt>
<a name="L182"></a><tt class="py-lineno">182</tt>  <tt class="py-line">        <tt class="py-name">p_hid_scaler</tt> <tt class="py-op">=</tt> <tt class="py-number">1.0</tt> </tt>
<a name="L183"></a><tt class="py-lineno">183</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">dp_scheduler</tt> <tt class="py-keyword">is</tt> <tt class="py-keyword">not</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L184"></a><tt class="py-lineno">184</tt>  <tt class="py-line">            <tt class="py-name">p_inp</tt><tt class="py-op">,</tt> <tt class="py-name">p_hid</tt> <tt class="py-op">=</tt> <tt class="py-name">dp_scheduler</tt><tt class="py-op">.</tt><tt id="link-28" class="py-name"><a title="mlp.schedulers.DropoutFixed.get_rate
mlp.schedulers.LearningRateFixed.get_rate
mlp.schedulers.LearningRateList.get_rate
mlp.schedulers.LearningRateNewBob.get_rate
mlp.schedulers.LearningRateScheduler.get_rate" class="py-name" href="#" onclick="return doclink('link-28', 'get_rate', 'link-18');">get_rate</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L185"></a><tt class="py-lineno">185</tt>  <tt class="py-line">            <tt class="py-name">p_hid_scaler</tt> <tt class="py-op">/=</tt> <tt class="py-name">p_hid</tt> </tt>
<a name="L186"></a><tt class="py-lineno">186</tt>  <tt class="py-line"> </tt>
<a name="L187"></a><tt class="py-lineno">187</tt>  <tt class="py-line">        <tt class="py-comment"># then back-prop through remaining layers</tt> </tt>
<a name="L188"></a><tt class="py-lineno">188</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">xrange</tt><tt class="py-op">(</tt><tt class="py-name">top_layer_idx</tt> <tt class="py-op">-</tt> <tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L189"></a><tt class="py-lineno">189</tt>  <tt class="py-line">            <tt class="py-comment"># print ograds.shape, "!hhhhhhhhhhh",( ograds*p_hid_scaler).shape,  self.layers[i - 1], self.activations[i]</tt> </tt>
<a name="L190"></a><tt class="py-lineno">190</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">deltas</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-29" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-29', 'layers', 'link-7');">layers</a></tt><tt class="py-op">[</tt><tt class="py-name">i</tt> <tt class="py-op">-</tt> <tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">.</tt>\ </tt>
<a name="L191"></a><tt class="py-lineno">191</tt>  <tt class="py-line">                <tt id="link-30" class="py-name" targets="Method mlp.convlin.ConvLinear_Opt.bprop()=mlp.convlin.ConvLinear_Opt-class.html#bprop,Method mlp.convlin.ConvMaxPool2D.bprop()=mlp.convlin.ConvMaxPool2D-class.html#bprop,Method mlp.convlin.ConvRelu_Opt.bprop()=mlp.convlin.ConvRelu_Opt-class.html#bprop,Method mlp.convlin.ConvSigmoid_Opt.bprop()=mlp.convlin.ConvSigmoid_Opt-class.html#bprop,Method mlp.layers.ComplexAbs.bprop()=mlp.layers.ComplexAbs-class.html#bprop,Method mlp.layers.ComplexLinear.bprop()=mlp.layers.ComplexLinear-class.html#bprop,Method mlp.layers.Layer.bprop()=mlp.layers.Layer-class.html#bprop,Method mlp.layers.Linear.bprop()=mlp.layers.Linear-class.html#bprop,Method mlp.layers.MLP.bprop()=mlp.layers.MLP-class.html#bprop,Method mlp.layers.Maxout.bprop()=mlp.layers.Maxout-class.html#bprop,Method mlp.layers.Relu.bprop()=mlp.layers.Relu-class.html#bprop,Method mlp.layers.Sigmoid.bprop()=mlp.layers.Sigmoid-class.html#bprop,Method mlp.layers.Softmax.bprop()=mlp.layers.Softmax-class.html#bprop,Method mlp.layers.Tanh.bprop()=mlp.layers.Tanh-class.html#bprop"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-30', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">activations</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt><tt class="py-op">*</tt><tt class="py-name">p_hid_scaler</tt><tt class="py-op">)</tt> </tt>
</div><a name="L192"></a><tt class="py-lineno">192</tt>  <tt class="py-line"> </tt>
<a name="MLP.add_layer"></a><div id="MLP.add_layer-def"><a name="L193"></a><tt class="py-lineno">193</tt> <a class="py-toggle" href="#" id="MLP.add_layer-toggle" onclick="return toggle('MLP.add_layer');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#add_layer">add_layer</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">layer</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.add_layer-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.add_layer-expanded"><a name="L194"></a><tt class="py-lineno">194</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-31" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-31', 'layers', 'link-7');">layers</a></tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">layer</tt><tt class="py-op">)</tt> </tt>
</div><a name="L195"></a><tt class="py-lineno">195</tt>  <tt class="py-line"> </tt>
<a name="MLP.set_layers"></a><div id="MLP.set_layers-def"><a name="L196"></a><tt class="py-lineno">196</tt> <a class="py-toggle" href="#" id="MLP.set_layers-toggle" onclick="return toggle('MLP.set_layers');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#set_layers">set_layers</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">layers</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.set_layers-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.set_layers-expanded"><a name="L197"></a><tt class="py-lineno">197</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-32" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-32', 'layers', 'link-7');">layers</a></tt> <tt class="py-op">=</tt> <tt id="link-33" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-33', 'layers', 'link-7');">layers</a></tt> </tt>
</div><a name="L198"></a><tt class="py-lineno">198</tt>  <tt class="py-line"> </tt>
<a name="MLP.get_name"></a><div id="MLP.get_name-def"><a name="L199"></a><tt class="py-lineno">199</tt> <a class="py-toggle" href="#" id="MLP.get_name-toggle" onclick="return toggle('MLP.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.get_name-expanded"><a name="L200"></a><tt class="py-lineno">200</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'mlp'</tt> </tt>
</div><a name="L201"></a><tt class="py-lineno">201</tt>  <tt class="py-line"> </tt>
<a name="MLP.remove_top_layer"></a><div id="MLP.remove_top_layer-def"><a name="L202"></a><tt class="py-lineno">202</tt> <a class="py-toggle" href="#" id="MLP.remove_top_layer-toggle" onclick="return toggle('MLP.remove_top_layer');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.MLP-class.html#remove_top_layer">remove_top_layer</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MLP.remove_top_layer-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="MLP.remove_top_layer-expanded"><a name="L203"></a><tt class="py-lineno">203</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-34" class="py-name"><a title="mlp.layers" class="py-name" href="#" onclick="return doclink('link-34', 'layers', 'link-7');">layers</a></tt><tt class="py-op">.</tt><tt class="py-name">pop</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L204"></a><tt class="py-lineno">204</tt>  <tt class="py-line"> </tt>
<a name="L205"></a><tt class="py-lineno">205</tt>  <tt class="py-line"> </tt>
<a name="Layer"></a><div id="Layer-def"><a name="L206"></a><tt class="py-lineno">206</tt> <a class="py-toggle" href="#" id="Layer-toggle" onclick="return toggle('Layer');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html">Layer</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Layer-expanded"><a name="L207"></a><tt class="py-lineno">207</tt>  <tt class="py-line"> </tt>
<a name="L208"></a><tt class="py-lineno">208</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L209"></a><tt class="py-lineno">209</tt>  <tt class="py-line"><tt class="py-docstring">    Abstract class defining an interface for</tt> </tt>
<a name="L210"></a><tt class="py-lineno">210</tt>  <tt class="py-line"><tt class="py-docstring">    other transforms.</tt> </tt>
<a name="L211"></a><tt class="py-lineno">211</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L212"></a><tt class="py-lineno">212</tt>  <tt class="py-line"> </tt>
<a name="Layer.__init__"></a><div id="Layer.__init__-def"><a name="L213"></a><tt class="py-lineno">213</tt> <a class="py-toggle" href="#" id="Layer.__init__-toggle" onclick="return toggle('Layer.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.__init__-expanded"><a name="L214"></a><tt class="py-lineno">214</tt>  <tt class="py-line"> </tt>
<a name="L215"></a><tt class="py-lineno">215</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rng</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L216"></a><tt class="py-lineno">216</tt>  <tt class="py-line">            <tt class="py-name">seed</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-number">2015</tt><tt class="py-op">,</tt> <tt class="py-number">10</tt><tt class="py-op">,</tt> <tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
<a name="L217"></a><tt class="py-lineno">217</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">random</tt><tt class="py-op">.</tt><tt class="py-name">RandomState</tt><tt class="py-op">(</tt><tt class="py-name">seed</tt><tt class="py-op">)</tt> </tt>
<a name="L218"></a><tt class="py-lineno">218</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L219"></a><tt class="py-lineno">219</tt>  <tt class="py-line">            <tt class="py-comment"># print "inherited"</tt> </tt>
<a name="L220"></a><tt class="py-lineno">220</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt> <tt class="py-op">=</tt> <tt class="py-name">rng</tt> </tt>
</div><a name="L221"></a><tt class="py-lineno">221</tt>  <tt class="py-line"> </tt>
<a name="Layer.fprop"></a><div id="Layer.fprop-def"><a name="L222"></a><tt class="py-lineno">222</tt> <a class="py-toggle" href="#" id="Layer.fprop-toggle" onclick="return toggle('Layer.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.fprop-expanded"><a name="L223"></a><tt class="py-lineno">223</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L224"></a><tt class="py-lineno">224</tt>  <tt class="py-line"><tt class="py-docstring">        Implements a forward propagation through the i-th layer, that is</tt> </tt>
<a name="L225"></a><tt class="py-lineno">225</tt>  <tt class="py-line"><tt class="py-docstring">        some form of:</tt> </tt>
<a name="L226"></a><tt class="py-lineno">226</tt>  <tt class="py-line"><tt class="py-docstring">           $a^{i} = xW^{i} + b^{i}$</tt> </tt>
<a name="L227"></a><tt class="py-lineno">227</tt>  <tt class="py-line"><tt class="py-docstring">           $h^{i} = f^{i}(a^{i})$</tt> </tt>
<a name="L228"></a><tt class="py-lineno">228</tt>  <tt class="py-line"><tt class="py-docstring">        with f^{i}, W^{i}, b^{i} denoting a non-linearity, weight matrix and</tt> </tt>
<a name="L229"></a><tt class="py-lineno">229</tt>  <tt class="py-line"><tt class="py-docstring">        biases at the i-th layer, respectively and x denoting inputs.</tt> </tt>
<a name="L230"></a><tt class="py-lineno">230</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L231"></a><tt class="py-lineno">231</tt>  <tt class="py-line"><tt class="py-docstring">        :param inputs: matrix of features $(x)$ or the output of the previous layer $h^{i-1}$</tt> </tt>
<a name="L232"></a><tt class="py-lineno">232</tt>  <tt class="py-line"><tt class="py-docstring">        :return: $h^i$, matrix of transformed by layer features</tt> </tt>
<a name="L233"></a><tt class="py-lineno">233</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L234"></a><tt class="py-lineno">234</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L235"></a><tt class="py-lineno">235</tt>  <tt class="py-line"> </tt>
<a name="Layer.bprop"></a><div id="Layer.bprop-def"><a name="L236"></a><tt class="py-lineno">236</tt> <a class="py-toggle" href="#" id="Layer.bprop-toggle" onclick="return toggle('Layer.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.bprop-expanded"><a name="L237"></a><tt class="py-lineno">237</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L238"></a><tt class="py-lineno">238</tt>  <tt class="py-line"><tt class="py-docstring">        Implements a backward propagation through the layer, that is, given</tt> </tt>
<a name="L239"></a><tt class="py-lineno">239</tt>  <tt class="py-line"><tt class="py-docstring">        $h^i$ denotes the output of the layer and $x^i$ the input, we compute:</tt> </tt>
<a name="L240"></a><tt class="py-lineno">240</tt>  <tt class="py-line"><tt class="py-docstring">        $dh^i/dx^i$ which by chain rule is $dh^i/da^i da^i/dx^i$</tt> </tt>
<a name="L241"></a><tt class="py-lineno">241</tt>  <tt class="py-line"><tt class="py-docstring">        $x^i$ could be either features $(x)$ or the output of the lower layer $h^{i-1}$</tt> </tt>
<a name="L242"></a><tt class="py-lineno">242</tt>  <tt class="py-line"><tt class="py-docstring">        :param h: it's an activation produced in forward pass</tt> </tt>
<a name="L243"></a><tt class="py-lineno">243</tt>  <tt class="py-line"><tt class="py-docstring">        :param igrads, error signal (or gradient) flowing to the layer, note,</tt> </tt>
<a name="L244"></a><tt class="py-lineno">244</tt>  <tt class="py-line"><tt class="py-docstring">               this in general case does not corresponds to 'deltas' used to update</tt> </tt>
<a name="L245"></a><tt class="py-lineno">245</tt>  <tt class="py-line"><tt class="py-docstring">               the layer's parameters, to get deltas ones need to multiply it with</tt> </tt>
<a name="L246"></a><tt class="py-lineno">246</tt>  <tt class="py-line"><tt class="py-docstring">               the $\partial h^{i}/ \partial a^{i}$ derivative</tt> </tt>
<a name="L247"></a><tt class="py-lineno">247</tt>  <tt class="py-line"><tt class="py-docstring">        :return: a tuple (deltas, ograds) where:</tt> </tt>
<a name="L248"></a><tt class="py-lineno">248</tt>  <tt class="py-line"><tt class="py-docstring">               $deltas = igrads *  \partial h^{i}/ \partial a^{i}$</tt> </tt>
<a name="L249"></a><tt class="py-lineno">249</tt>  <tt class="py-line"><tt class="py-docstring">               $ograds = deltas \times \partial a^{i}/ \partial x^{i}$</tt> </tt>
<a name="L250"></a><tt class="py-lineno">250</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L251"></a><tt class="py-lineno">251</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L252"></a><tt class="py-lineno">252</tt>  <tt class="py-line"> </tt>
<a name="Layer.bprop_cost"></a><div id="Layer.bprop_cost-def"><a name="L253"></a><tt class="py-lineno">253</tt> <a class="py-toggle" href="#" id="Layer.bprop_cost-toggle" onclick="return toggle('Layer.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.bprop_cost-expanded"><a name="L254"></a><tt class="py-lineno">254</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L255"></a><tt class="py-lineno">255</tt>  <tt class="py-line"><tt class="py-docstring">        Implements a backward propagation in case the layer directly</tt> </tt>
<a name="L256"></a><tt class="py-lineno">256</tt>  <tt class="py-line"><tt class="py-docstring">        deals with the optimised cost (i.e. the top layer)</tt> </tt>
<a name="L257"></a><tt class="py-lineno">257</tt>  <tt class="py-line"><tt class="py-docstring">        By default, method should implement a back-prop for default cost, that is</tt> </tt>
<a name="L258"></a><tt class="py-lineno">258</tt>  <tt class="py-line"><tt class="py-docstring">        the one that is natural to the layer's output, i.e.:</tt> </tt>
<a name="L259"></a><tt class="py-lineno">259</tt>  <tt class="py-line"><tt class="py-docstring">        linear -&gt; mse, softmax -&gt; cross-entropy, sigmoid -&gt; binary cross-entropy</tt> </tt>
<a name="L260"></a><tt class="py-lineno">260</tt>  <tt class="py-line"><tt class="py-docstring">        :param $h$: it's an activation produced in forward pass</tt> </tt>
<a name="L261"></a><tt class="py-lineno">261</tt>  <tt class="py-line"><tt class="py-docstring">        :param igrads, error signal (or gradient) flowing to the layer, note,</tt> </tt>
<a name="L262"></a><tt class="py-lineno">262</tt>  <tt class="py-line"><tt class="py-docstring">               this in general case does not corresponds to 'deltas' used to update</tt> </tt>
<a name="L263"></a><tt class="py-lineno">263</tt>  <tt class="py-line"><tt class="py-docstring">               the layer's parameters, to get deltas ones need to multiply it with</tt> </tt>
<a name="L264"></a><tt class="py-lineno">264</tt>  <tt class="py-line"><tt class="py-docstring">               the $\partial h^{i}/ \partial a^{i}$ derivative</tt> </tt>
<a name="L265"></a><tt class="py-lineno">265</tt>  <tt class="py-line"><tt class="py-docstring">        :return: a tuple (deltas, ograds) where:</tt> </tt>
<a name="L266"></a><tt class="py-lineno">266</tt>  <tt class="py-line"><tt class="py-docstring">               $deltas = igrads * \partial h^{i}/ \partial a^{i}$</tt> </tt>
<a name="L267"></a><tt class="py-lineno">267</tt>  <tt class="py-line"><tt class="py-docstring">               $ograds = deltas \times \partial a^{i}/ \partial x^{i}$</tt> </tt>
<a name="L268"></a><tt class="py-lineno">268</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L269"></a><tt class="py-lineno">269</tt>  <tt class="py-line"> </tt>
<a name="L270"></a><tt class="py-lineno">270</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L271"></a><tt class="py-lineno">271</tt>  <tt class="py-line"> </tt>
<a name="Layer.pgrads"></a><div id="Layer.pgrads-def"><a name="L272"></a><tt class="py-lineno">272</tt> <a class="py-toggle" href="#" id="Layer.pgrads-toggle" onclick="return toggle('Layer.pgrads');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#pgrads">pgrads</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">,</tt> <tt class="py-param">deltas</tt><tt class="py-op">,</tt> <tt class="py-op">**</tt><tt class="py-param">kwargs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.pgrads-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.pgrads-expanded"><a name="L273"></a><tt class="py-lineno">273</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L274"></a><tt class="py-lineno">274</tt>  <tt class="py-line"><tt class="py-docstring">        Return gradients w.r.t parameters</tt> </tt>
<a name="L275"></a><tt class="py-lineno">275</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L276"></a><tt class="py-lineno">276</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L277"></a><tt class="py-lineno">277</tt>  <tt class="py-line"> </tt>
<a name="Layer.get_params"></a><div id="Layer.get_params-def"><a name="L278"></a><tt class="py-lineno">278</tt> <a class="py-toggle" href="#" id="Layer.get_params-toggle" onclick="return toggle('Layer.get_params');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#get_params">get_params</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.get_params-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.get_params-expanded"><a name="L279"></a><tt class="py-lineno">279</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L280"></a><tt class="py-lineno">280</tt>  <tt class="py-line"> </tt>
<a name="Layer.set_params"></a><div id="Layer.set_params-def"><a name="L281"></a><tt class="py-lineno">281</tt> <a class="py-toggle" href="#" id="Layer.set_params-toggle" onclick="return toggle('Layer.set_params');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#set_params">set_params</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.set_params-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.set_params-expanded"><a name="L282"></a><tt class="py-lineno">282</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L283"></a><tt class="py-lineno">283</tt>  <tt class="py-line"> </tt>
<a name="Layer.get_name"></a><div id="Layer.get_name-def"><a name="L284"></a><tt class="py-lineno">284</tt> <a class="py-toggle" href="#" id="Layer.get_name-toggle" onclick="return toggle('Layer.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Layer-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Layer.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Layer.get_name-expanded"><a name="L285"></a><tt class="py-lineno">285</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'abstract_layer'</tt> </tt>
</div></div><a name="L286"></a><tt class="py-lineno">286</tt>  <tt class="py-line"> </tt>
<a name="L287"></a><tt class="py-lineno">287</tt>  <tt class="py-line"> </tt>
<a name="Linear"></a><div id="Linear-def"><a name="L288"></a><tt class="py-lineno">288</tt> <a class="py-toggle" href="#" id="Linear-toggle" onclick="return toggle('Linear');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html">Linear</a><tt class="py-op">(</tt><tt class="py-base-class">Layer</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Linear-expanded"><a name="L289"></a><tt class="py-lineno">289</tt>  <tt class="py-line"> </tt>
<a name="Linear.__init__"></a><div id="Linear.__init__-def"><a name="L290"></a><tt class="py-lineno">290</tt> <a class="py-toggle" href="#" id="Linear.__init__-toggle" onclick="return toggle('Linear.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L291"></a><tt class="py-lineno">291</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L292"></a><tt class="py-lineno">292</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.__init__-expanded"><a name="L293"></a><tt class="py-lineno">293</tt>  <tt class="py-line"> </tt>
<a name="L294"></a><tt class="py-lineno">294</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-35" class="py-name" targets="Class mlp.layers.Linear=mlp.layers.Linear-class.html"><a title="mlp.layers.Linear" class="py-name" href="#" onclick="return doclink('link-35', 'Linear', 'link-35');">Linear</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-36" class="py-name" targets="Method mlp.convlin.ConvLinear_Opt.__init__()=mlp.convlin.ConvLinear_Opt-class.html#__init__,Method mlp.convlin.ConvMaxPool2D.__init__()=mlp.convlin.ConvMaxPool2D-class.html#__init__,Method mlp.convlin.ConvRelu_Opt.__init__()=mlp.convlin.ConvRelu_Opt-class.html#__init__,Method mlp.convlin.ConvSigmoid_Opt.__init__()=mlp.convlin.ConvSigmoid_Opt-class.html#__init__,Method mlp.dataset.DataProvider.__init__()=mlp.dataset.DataProvider-class.html#__init__,Method mlp.dataset.FuncDataProvider.__init__()=mlp.dataset.FuncDataProvider-class.html#__init__,Method mlp.dataset.MACLDataProvider.__init__()=mlp.dataset.MACLDataProvider-class.html#__init__,Method mlp.dataset.MetOfficeDataProvider.__init__()=mlp.dataset.MetOfficeDataProvider-class.html#__init__,Method mlp.dataset.mACLEnum.__init__()=mlp.dataset.mACLEnum-class.html#__init__,Method mlp.layers.ComplexAbs.__init__()=mlp.layers.ComplexAbs-class.html#__init__,Method mlp.layers.ComplexLinear.__init__()=mlp.layers.ComplexLinear-class.html#__init__,Method mlp.layers.Layer.__init__()=mlp.layers.Layer-class.html#__init__,Method mlp.layers.Linear.__init__()=mlp.layers.Linear-class.html#__init__,Method mlp.layers.MLP.__init__()=mlp.layers.MLP-class.html#__init__,Method mlp.layers.Maxout.__init__()=mlp.layers.Maxout-class.html#__init__,Method mlp.layers.Relu.__init__()=mlp.layers.Relu-class.html#__init__,Method mlp.layers.Sigmoid.__init__()=mlp.layers.Sigmoid-class.html#__init__,Method mlp.layers.Softmax.__init__()=mlp.layers.Softmax-class.html#__init__,Method mlp.layers.Tanh.__init__()=mlp.layers.Tanh-class.html#__init__,Method mlp.optimisers.SGDOptimiser.__init__()=mlp.optimisers.SGDOptimiser-class.html#__init__,Method mlp.schedulers.DropoutFixed.__init__()=mlp.schedulers.DropoutFixed-class.html#__init__,Method mlp.schedulers.LearningRateFixed.__init__()=mlp.schedulers.LearningRateFixed-class.html#__init__,Method mlp.schedulers.LearningRateList.__init__()=mlp.schedulers.LearningRateList-class.html#__init__,Method mlp.schedulers.LearningRateNewBob.__init__()=mlp.schedulers.LearningRateNewBob-class.html#__init__,Method mlp.schedulers.LearningRateScheduler.__init__()=mlp.schedulers.LearningRateScheduler-class.html#__init__"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-36', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">rng</tt><tt class="py-op">=</tt><tt class="py-name">rng</tt><tt class="py-op">)</tt> </tt>
<a name="L295"></a><tt class="py-lineno">295</tt>  <tt class="py-line"> </tt>
<a name="L296"></a><tt class="py-lineno">296</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">idim</tt> <tt class="py-op">=</tt> <tt class="py-name">idim</tt> </tt>
<a name="L297"></a><tt class="py-lineno">297</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">odim</tt> <tt class="py-op">=</tt> <tt class="py-name">odim</tt> </tt>
<a name="L298"></a><tt class="py-lineno">298</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">irange</tt> <tt class="py-op">=</tt> <tt class="py-name">irange</tt> </tt>
<a name="L299"></a><tt class="py-lineno">299</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">rng</tt><tt class="py-op">.</tt><tt class="py-name">uniform</tt><tt class="py-op">(</tt> </tt>
<a name="L300"></a><tt class="py-lineno">300</tt>  <tt class="py-line">            <tt class="py-op">-</tt><tt class="py-name">irange</tt><tt class="py-op">,</tt> <tt class="py-name">irange</tt><tt class="py-op">,</tt> </tt>
<a name="L301"></a><tt class="py-lineno">301</tt>  <tt class="py-line">            <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">odim</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L302"></a><tt class="py-lineno">302</tt>  <tt class="py-line">        <tt class="py-comment"># print self.rng, irange</tt> </tt>
<a name="L303"></a><tt class="py-lineno">303</tt>  <tt class="py-line">        <tt class="py-comment"># print self.W</tt> </tt>
<a name="L304"></a><tt class="py-lineno">304</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">zeros</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">odim</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">dtype</tt><tt class="py-op">=</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">float32</tt><tt class="py-op">)</tt> </tt>
</div><a name="L305"></a><tt class="py-lineno">305</tt>  <tt class="py-line"> </tt>
<a name="Linear.fprop"></a><div id="Linear.fprop-def"><a name="L306"></a><tt class="py-lineno">306</tt> <a class="py-toggle" href="#" id="Linear.fprop-toggle" onclick="return toggle('Linear.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.fprop-expanded"><a name="L307"></a><tt class="py-lineno">307</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L308"></a><tt class="py-lineno">308</tt>  <tt class="py-line"><tt class="py-docstring">        Implements a forward propagation through the i-th layer, that is</tt> </tt>
<a name="L309"></a><tt class="py-lineno">309</tt>  <tt class="py-line"><tt class="py-docstring">        some form of:</tt> </tt>
<a name="L310"></a><tt class="py-lineno">310</tt>  <tt class="py-line"><tt class="py-docstring">           $a^{i} = xW^{i} + b^{i}$</tt> </tt>
<a name="L311"></a><tt class="py-lineno">311</tt>  <tt class="py-line"><tt class="py-docstring">           $h^{i} = f^{i}(a^{i})$</tt> </tt>
<a name="L312"></a><tt class="py-lineno">312</tt>  <tt class="py-line"><tt class="py-docstring">        with $f^{i}, W^{i}, b^{i}$ denoting a non-linearity, weight matrix and</tt> </tt>
<a name="L313"></a><tt class="py-lineno">313</tt>  <tt class="py-line"><tt class="py-docstring">        biases of this (i-th) layer, respectively and $x$ denoting inputs.</tt> </tt>
<a name="L314"></a><tt class="py-lineno">314</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L315"></a><tt class="py-lineno">315</tt>  <tt class="py-line"><tt class="py-docstring">        :param inputs: matrix of features $(x)$ or the output of the previous layer $h^{i-1}$</tt> </tt>
<a name="L316"></a><tt class="py-lineno">316</tt>  <tt class="py-line"><tt class="py-docstring">        :return: $h^i$, matrix of transformed by layer features</tt> </tt>
<a name="L317"></a><tt class="py-lineno">317</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L318"></a><tt class="py-lineno">318</tt>  <tt class="py-line"> </tt>
<a name="L319"></a><tt class="py-lineno">319</tt>  <tt class="py-line">        <tt class="py-comment"># input comes from 4D convolutional tensor, reshape to expected shape</tt> </tt>
<a name="L320"></a><tt class="py-lineno">320</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt><tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L321"></a><tt class="py-lineno">321</tt>  <tt class="py-line">            <tt class="py-name">inputs</tt> <tt class="py-op">=</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L322"></a><tt class="py-lineno">322</tt>  <tt class="py-line"> </tt>
<a name="L323"></a><tt class="py-lineno">323</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> </tt>
<a name="L324"></a><tt class="py-lineno">324</tt>  <tt class="py-line">        <tt class="py-comment"># here f() is an identity function, so just return a linear</tt> </tt>
<a name="L325"></a><tt class="py-lineno">325</tt>  <tt class="py-line">        <tt class="py-comment"># transformation</tt> </tt>
<a name="L326"></a><tt class="py-lineno">326</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">a</tt> </tt>
</div><a name="L327"></a><tt class="py-lineno">327</tt>  <tt class="py-line"> </tt>
<a name="Linear.bprop"></a><div id="Linear.bprop-def"><a name="L328"></a><tt class="py-lineno">328</tt> <a class="py-toggle" href="#" id="Linear.bprop-toggle" onclick="return toggle('Linear.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.bprop-expanded"><a name="L329"></a><tt class="py-lineno">329</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L330"></a><tt class="py-lineno">330</tt>  <tt class="py-line"><tt class="py-docstring">        Implements a backward propagation through the layer, that is, given</tt> </tt>
<a name="L331"></a><tt class="py-lineno">331</tt>  <tt class="py-line"><tt class="py-docstring">        $h^i$ denotes the output of the layer and $x^i$ the input, we compute:</tt> </tt>
<a name="L332"></a><tt class="py-lineno">332</tt>  <tt class="py-line"><tt class="py-docstring">        $dh^i/dx^i$ which by chain rule is $dh^i/da^i da^i/dx^i$</tt> </tt>
<a name="L333"></a><tt class="py-lineno">333</tt>  <tt class="py-line"><tt class="py-docstring">        $x^i$ could be either features $(x)$ or the output of the lower layer $h^{i-1}$</tt> </tt>
<a name="L334"></a><tt class="py-lineno">334</tt>  <tt class="py-line"><tt class="py-docstring">        :param h: it's an activation produced in forward pass</tt> </tt>
<a name="L335"></a><tt class="py-lineno">335</tt>  <tt class="py-line"><tt class="py-docstring">        :param igrads, error signal (or gradient) flowing to the layer, note,</tt> </tt>
<a name="L336"></a><tt class="py-lineno">336</tt>  <tt class="py-line"><tt class="py-docstring">               this in general case does not corresponds to 'deltas' used to update</tt> </tt>
<a name="L337"></a><tt class="py-lineno">337</tt>  <tt class="py-line"><tt class="py-docstring">               the layer's parameters, to get deltas ones need to multiply it with</tt> </tt>
<a name="L338"></a><tt class="py-lineno">338</tt>  <tt class="py-line"><tt class="py-docstring">               the $\partial h^{i}/ \partial a^{i}$ derivative</tt> </tt>
<a name="L339"></a><tt class="py-lineno">339</tt>  <tt class="py-line"><tt class="py-docstring">        :return: a tuple (deltas, ograds) where:</tt> </tt>
<a name="L340"></a><tt class="py-lineno">340</tt>  <tt class="py-line"><tt class="py-docstring">               $deltas = igrads *  \partial h^{i}/ \partial a^{i}$</tt> </tt>
<a name="L341"></a><tt class="py-lineno">341</tt>  <tt class="py-line"><tt class="py-docstring">               $ograds = deltas \times \partial a^{i}/ \partial x^{i}$</tt> </tt>
<a name="L342"></a><tt class="py-lineno">342</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L343"></a><tt class="py-lineno">343</tt>  <tt class="py-line"> </tt>
<a name="L344"></a><tt class="py-lineno">344</tt>  <tt class="py-line">        <tt class="py-comment"># since $df^i/da^i = 1$  (f is assumed identity function),</tt> </tt>
<a name="L345"></a><tt class="py-lineno">345</tt>  <tt class="py-line">        <tt class="py-comment"># deltas are in fact the same as igrads</tt> </tt>
<a name="L346"></a><tt class="py-lineno">346</tt>  <tt class="py-line">        <tt class="py-comment"># print igrads.shape</tt> </tt>
<a name="L347"></a><tt class="py-lineno">347</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt><tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L348"></a><tt class="py-lineno">348</tt>  <tt class="py-line">            <tt class="py-name">igrads</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L349"></a><tt class="py-lineno">349</tt>  <tt class="py-line">        <tt class="py-comment"># print igrads.shape</tt> </tt>
<a name="L350"></a><tt class="py-lineno">350</tt>  <tt class="py-line">        <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt> </tt>
<a name="L351"></a><tt class="py-lineno">351</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">igrads</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> </tt>
</div><a name="L352"></a><tt class="py-lineno">352</tt>  <tt class="py-line"> </tt>
<a name="Linear.bprop_cost"></a><div id="Linear.bprop_cost-def"><a name="L353"></a><tt class="py-lineno">353</tt> <a class="py-toggle" href="#" id="Linear.bprop_cost-toggle" onclick="return toggle('Linear.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.bprop_cost-expanded"><a name="L354"></a><tt class="py-lineno">354</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L355"></a><tt class="py-lineno">355</tt>  <tt class="py-line"><tt class="py-docstring">        Implements a backward propagation in case the layer directly</tt> </tt>
<a name="L356"></a><tt class="py-lineno">356</tt>  <tt class="py-line"><tt class="py-docstring">        deals with the optimised cost (i.e. the top layer)</tt> </tt>
<a name="L357"></a><tt class="py-lineno">357</tt>  <tt class="py-line"><tt class="py-docstring">        By default, method should implement a back-prop for default cost, that is</tt> </tt>
<a name="L358"></a><tt class="py-lineno">358</tt>  <tt class="py-line"><tt class="py-docstring">        the one that is natural to the layer's output, i.e.:</tt> </tt>
<a name="L359"></a><tt class="py-lineno">359</tt>  <tt class="py-line"><tt class="py-docstring">        linear -&gt; mse, softmax -&gt; cross-entropy, sigmoid -&gt; binary cross-entropy</tt> </tt>
<a name="L360"></a><tt class="py-lineno">360</tt>  <tt class="py-line"><tt class="py-docstring">        :param $h$: it's an activation produced in forward pass</tt> </tt>
<a name="L361"></a><tt class="py-lineno">361</tt>  <tt class="py-line"><tt class="py-docstring">        :param igrads, error signal (or gradient) flowing to the layer, note,</tt> </tt>
<a name="L362"></a><tt class="py-lineno">362</tt>  <tt class="py-line"><tt class="py-docstring">               this in general case does not corresponds to 'deltas' used to update</tt> </tt>
<a name="L363"></a><tt class="py-lineno">363</tt>  <tt class="py-line"><tt class="py-docstring">               the layer's parameters, to get deltas ones need to multiply it with</tt> </tt>
<a name="L364"></a><tt class="py-lineno">364</tt>  <tt class="py-line"><tt class="py-docstring">               the $\partial h^{i}/ \partial a^{i}$ derivative</tt> </tt>
<a name="L365"></a><tt class="py-lineno">365</tt>  <tt class="py-line"><tt class="py-docstring">        :return: a tuple (deltas, ograds) where:</tt> </tt>
<a name="L366"></a><tt class="py-lineno">366</tt>  <tt class="py-line"><tt class="py-docstring">               $deltas = igrads * \partial h^{i}/ \partial a^{i}$</tt> </tt>
<a name="L367"></a><tt class="py-lineno">367</tt>  <tt class="py-line"><tt class="py-docstring">               $ograds = deltas \times \partial a^{i}/ \partial x^{i}$</tt> </tt>
<a name="L368"></a><tt class="py-lineno">368</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L369"></a><tt class="py-lineno">369</tt>  <tt class="py-line"> </tt>
<a name="L370"></a><tt class="py-lineno">370</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-37" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-37', 'cost', 'link-4');">cost</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt> <tt class="py-keyword">or</tt> <tt id="link-38" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-38', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-39" class="py-name" targets="Method mlp.convlin.ConvLinear_Opt.get_name()=mlp.convlin.ConvLinear_Opt-class.html#get_name,Method mlp.convlin.ConvMaxPool2D.get_name()=mlp.convlin.ConvMaxPool2D-class.html#get_name,Method mlp.convlin.ConvRelu_Opt.get_name()=mlp.convlin.ConvRelu_Opt-class.html#get_name,Method mlp.convlin.ConvSigmoid_Opt.get_name()=mlp.convlin.ConvSigmoid_Opt-class.html#get_name,Method mlp.costs.CECost.get_name()=mlp.costs.CECost-class.html#get_name,Method mlp.costs.Cost.get_name()=mlp.costs.Cost-class.html#get_name,Method mlp.costs.MSECost.get_name()=mlp.costs.MSECost-class.html#get_name,Method mlp.layers.ComplexAbs.get_name()=mlp.layers.ComplexAbs-class.html#get_name,Method mlp.layers.ComplexLinear.get_name()=mlp.layers.ComplexLinear-class.html#get_name,Method mlp.layers.Layer.get_name()=mlp.layers.Layer-class.html#get_name,Method mlp.layers.Linear.get_name()=mlp.layers.Linear-class.html#get_name,Method mlp.layers.MLP.get_name()=mlp.layers.MLP-class.html#get_name,Method mlp.layers.Maxout.get_name()=mlp.layers.Maxout-class.html#get_name,Method mlp.layers.Relu.get_name()=mlp.layers.Relu-class.html#get_name,Method mlp.layers.Sigmoid.get_name()=mlp.layers.Sigmoid-class.html#get_name,Method mlp.layers.Softmax.get_name()=mlp.layers.Softmax-class.html#get_name,Method mlp.layers.Tanh.get_name()=mlp.layers.Tanh-class.html#get_name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-39', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">'mse'</tt><tt class="py-op">:</tt> </tt>
<a name="L371"></a><tt class="py-lineno">371</tt>  <tt class="py-line">            <tt class="py-comment"># for linear layer and mean square error cost,</tt> </tt>
<a name="L372"></a><tt class="py-lineno">372</tt>  <tt class="py-line">            <tt class="py-comment"># cost back-prop is the same as standard back-prop</tt> </tt>
<a name="L373"></a><tt class="py-lineno">373</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-40" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-40', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">)</tt> </tt>
<a name="L374"></a><tt class="py-lineno">374</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L375"></a><tt class="py-lineno">375</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Linear.bprop_cost method not implemented '</tt> </tt>
<a name="L376"></a><tt class="py-lineno">376</tt>  <tt class="py-line">                                      <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-41" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-41', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-42" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-42', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L377"></a><tt class="py-lineno">377</tt>  <tt class="py-line"> </tt>
<a name="Linear.pgrads"></a><div id="Linear.pgrads-def"><a name="L378"></a><tt class="py-lineno">378</tt> <a class="py-toggle" href="#" id="Linear.pgrads-toggle" onclick="return toggle('Linear.pgrads');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#pgrads">pgrads</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">,</tt> <tt class="py-param">deltas</tt><tt class="py-op">,</tt> <tt class="py-param">l1_weight</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-param">l2_weight</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.pgrads-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.pgrads-expanded"><a name="L379"></a><tt class="py-lineno">379</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L380"></a><tt class="py-lineno">380</tt>  <tt class="py-line"><tt class="py-docstring">        Return gradients w.r.t parameters</tt> </tt>
<a name="L381"></a><tt class="py-lineno">381</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L382"></a><tt class="py-lineno">382</tt>  <tt class="py-line"><tt class="py-docstring">        :param inputs, input to the i-th layer</tt> </tt>
<a name="L383"></a><tt class="py-lineno">383</tt>  <tt class="py-line"><tt class="py-docstring">        :param deltas, deltas computed in bprop stage up to -ith layer</tt> </tt>
<a name="L384"></a><tt class="py-lineno">384</tt>  <tt class="py-line"><tt class="py-docstring">        :param kwargs, key-value optional arguments</tt> </tt>
<a name="L385"></a><tt class="py-lineno">385</tt>  <tt class="py-line"><tt class="py-docstring">        :return list of grads w.r.t parameters dE/dW and dE/db in *exactly*</tt> </tt>
<a name="L386"></a><tt class="py-lineno">386</tt>  <tt class="py-line"><tt class="py-docstring">                the same order as the params are returned by get_params()</tt> </tt>
<a name="L387"></a><tt class="py-lineno">387</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L388"></a><tt class="py-lineno">388</tt>  <tt class="py-line"><tt class="py-docstring">        Note: deltas here contain the whole chain rule leading</tt> </tt>
<a name="L389"></a><tt class="py-lineno">389</tt>  <tt class="py-line"><tt class="py-docstring">        from the cost up to the the i-th layer, i.e.</tt> </tt>
<a name="L390"></a><tt class="py-lineno">390</tt>  <tt class="py-line"><tt class="py-docstring">        $\partial E/\partial y^{L}  \partial y^{L}/ \partial a^{L} \partial a^{L}/ \partial h^{L-1} \partial h^{L-1}/ \partial a^{L-1} ... \partial h^{i}/ \partial a^{i}$</tt> </tt>
<a name="L391"></a><tt class="py-lineno">391</tt>  <tt class="py-line"><tt class="py-docstring">        and here we are just asking about</tt> </tt>
<a name="L392"></a><tt class="py-lineno">392</tt>  <tt class="py-line"><tt class="py-docstring">          1) $\partial a^{i}/ \partial W^{i}$ and 2) $\partial a^{i}/ \partial b^{i}$</tt> </tt>
<a name="L393"></a><tt class="py-lineno">393</tt>  <tt class="py-line"><tt class="py-docstring">        since W and b are only layer's parameters</tt> </tt>
<a name="L394"></a><tt class="py-lineno">394</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L395"></a><tt class="py-lineno">395</tt>  <tt class="py-line"> </tt>
<a name="L396"></a><tt class="py-lineno">396</tt>  <tt class="py-line">        <tt class="py-comment"># input comes from 4D convolutional tensor, reshape to expected shape</tt> </tt>
<a name="L397"></a><tt class="py-lineno">397</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L398"></a><tt class="py-lineno">398</tt>  <tt class="py-line">            <tt class="py-name">inputs</tt> <tt class="py-op">=</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L399"></a><tt class="py-lineno">399</tt>  <tt class="py-line"> </tt>
<a name="L400"></a><tt class="py-lineno">400</tt>  <tt class="py-line">        <tt class="py-comment"># you could basically use different scalers for biases</tt> </tt>
<a name="L401"></a><tt class="py-lineno">401</tt>  <tt class="py-line">        <tt class="py-comment"># and weights, but it is not implemented here like this</tt> </tt>
<a name="L402"></a><tt class="py-lineno">402</tt>  <tt class="py-line">        <tt class="py-name">l2_W_penalty</tt><tt class="py-op">,</tt> <tt class="py-name">l2_b_penalty</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt> </tt>
<a name="L403"></a><tt class="py-lineno">403</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">l2_weight</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">:</tt> </tt>
<a name="L404"></a><tt class="py-lineno">404</tt>  <tt class="py-line">            <tt class="py-name">l2_W_penalty</tt> <tt class="py-op">=</tt> <tt class="py-name">l2_weight</tt><tt class="py-op">*</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt> </tt>
<a name="L405"></a><tt class="py-lineno">405</tt>  <tt class="py-line">            <tt class="py-name">l2_b_penalty</tt> <tt class="py-op">=</tt> <tt class="py-name">l2_weight</tt><tt class="py-op">*</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> </tt>
<a name="L406"></a><tt class="py-lineno">406</tt>  <tt class="py-line"> </tt>
<a name="L407"></a><tt class="py-lineno">407</tt>  <tt class="py-line">        <tt class="py-name">l1_W_penalty</tt><tt class="py-op">,</tt> <tt class="py-name">l1_b_penalty</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt> </tt>
<a name="L408"></a><tt class="py-lineno">408</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">l1_weight</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">:</tt> </tt>
<a name="L409"></a><tt class="py-lineno">409</tt>  <tt class="py-line">            <tt class="py-name">l1_W_penalty</tt> <tt class="py-op">=</tt> <tt class="py-name">l1_weight</tt><tt class="py-op">*</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">sign</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt><tt class="py-op">)</tt> </tt>
<a name="L410"></a><tt class="py-lineno">410</tt>  <tt class="py-line">            <tt class="py-name">l1_b_penalty</tt> <tt class="py-op">=</tt> <tt class="py-name">l1_weight</tt><tt class="py-op">*</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">sign</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt><tt class="py-op">)</tt> </tt>
<a name="L411"></a><tt class="py-lineno">411</tt>  <tt class="py-line"> </tt>
<a name="L412"></a><tt class="py-lineno">412</tt>  <tt class="py-line">        <tt class="py-name">grad_W</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">,</tt> <tt class="py-name">deltas</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-name">l2_W_penalty</tt> <tt class="py-op">+</tt> <tt class="py-name">l1_W_penalty</tt> </tt>
<a name="L413"></a><tt class="py-lineno">413</tt>  <tt class="py-line">        <tt class="py-name">grad_b</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">deltas</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-name">l2_b_penalty</tt> <tt class="py-op">+</tt> <tt class="py-name">l1_b_penalty</tt> </tt>
<a name="L414"></a><tt class="py-lineno">414</tt>  <tt class="py-line"> </tt>
<a name="L415"></a><tt class="py-lineno">415</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">[</tt><tt class="py-name">grad_W</tt><tt class="py-op">,</tt> <tt class="py-name">grad_b</tt><tt class="py-op">]</tt> </tt>
</div><a name="L416"></a><tt class="py-lineno">416</tt>  <tt class="py-line"> </tt>
<a name="Linear.get_params"></a><div id="Linear.get_params-def"><a name="L417"></a><tt class="py-lineno">417</tt> <a class="py-toggle" href="#" id="Linear.get_params-toggle" onclick="return toggle('Linear.get_params');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#get_params">get_params</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.get_params-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.get_params-expanded"><a name="L418"></a><tt class="py-lineno">418</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt><tt class="py-op">]</tt> </tt>
</div><a name="L419"></a><tt class="py-lineno">419</tt>  <tt class="py-line"> </tt>
<a name="Linear.set_params"></a><div id="Linear.set_params-def"><a name="L420"></a><tt class="py-lineno">420</tt> <a class="py-toggle" href="#" id="Linear.set_params-toggle" onclick="return toggle('Linear.set_params');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#set_params">set_params</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">params</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.set_params-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.set_params-expanded"><a name="L421"></a><tt class="py-lineno">421</tt>  <tt class="py-line">        <tt class="py-comment"># we do not make checks here, but the order on the list</tt> </tt>
<a name="L422"></a><tt class="py-lineno">422</tt>  <tt class="py-line">        <tt class="py-comment"># is assumed to be exactly the same as get_params() returns</tt> </tt>
<a name="L423"></a><tt class="py-lineno">423</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt> <tt class="py-op">=</tt> <tt class="py-name">params</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> </tt>
<a name="L424"></a><tt class="py-lineno">424</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> <tt class="py-op">=</tt> <tt class="py-name">params</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
</div><a name="L425"></a><tt class="py-lineno">425</tt>  <tt class="py-line"> </tt>
<a name="Linear.get_name"></a><div id="Linear.get_name-def"><a name="L426"></a><tt class="py-lineno">426</tt> <a class="py-toggle" href="#" id="Linear.get_name-toggle" onclick="return toggle('Linear.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Linear-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Linear.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Linear.get_name-expanded"><a name="L427"></a><tt class="py-lineno">427</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'linear'</tt> </tt>
</div></div><a name="L428"></a><tt class="py-lineno">428</tt>  <tt class="py-line"> </tt>
<a name="L429"></a><tt class="py-lineno">429</tt>  <tt class="py-line"> </tt>
<a name="Sigmoid"></a><div id="Sigmoid-def"><a name="L430"></a><tt class="py-lineno">430</tt> <a class="py-toggle" href="#" id="Sigmoid-toggle" onclick="return toggle('Sigmoid');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Sigmoid-class.html">Sigmoid</a><tt class="py-op">(</tt><tt class="py-base-class">Linear</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Sigmoid-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Sigmoid-expanded"><a name="L431"></a><tt class="py-lineno">431</tt>  <tt class="py-line"> </tt>
<a name="Sigmoid.__init__"></a><div id="Sigmoid.__init__-def"><a name="L432"></a><tt class="py-lineno">432</tt> <a class="py-toggle" href="#" id="Sigmoid.__init__-toggle" onclick="return toggle('Sigmoid.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Sigmoid-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt>  <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L433"></a><tt class="py-lineno">433</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L434"></a><tt class="py-lineno">434</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Sigmoid.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Sigmoid.__init__-expanded"><a name="L435"></a><tt class="py-lineno">435</tt>  <tt class="py-line"> </tt>
<a name="L436"></a><tt class="py-lineno">436</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-43" class="py-name" targets="Class mlp.layers.Sigmoid=mlp.layers.Sigmoid-class.html"><a title="mlp.layers.Sigmoid" class="py-name" href="#" onclick="return doclink('link-43', 'Sigmoid', 'link-43');">Sigmoid</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-44" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-44', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> <tt class="py-name">odim</tt><tt class="py-op">,</tt> <tt class="py-name">rng</tt><tt class="py-op">,</tt> <tt class="py-name">irange</tt><tt class="py-op">)</tt> </tt>
</div><a name="L437"></a><tt class="py-lineno">437</tt>  <tt class="py-line"> </tt>
<a name="Sigmoid.fprop"></a><div id="Sigmoid.fprop-def"><a name="L438"></a><tt class="py-lineno">438</tt> <a class="py-toggle" href="#" id="Sigmoid.fprop-toggle" onclick="return toggle('Sigmoid.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Sigmoid-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Sigmoid.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Sigmoid.fprop-expanded"><a name="L439"></a><tt class="py-lineno">439</tt>  <tt class="py-line">        <tt class="py-comment"># get the linear activations</tt> </tt>
<a name="L440"></a><tt class="py-lineno">440</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-45" class="py-name"><a title="mlp.layers.Sigmoid" class="py-name" href="#" onclick="return doclink('link-45', 'Sigmoid', 'link-43');">Sigmoid</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-46" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-46', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">)</tt> </tt>
<a name="L441"></a><tt class="py-lineno">441</tt>  <tt class="py-line">        <tt class="py-comment"># stabilise the exp() computation in case some values in</tt> </tt>
<a name="L442"></a><tt class="py-lineno">442</tt>  <tt class="py-line">        <tt class="py-comment">#'a' get very negative. We limit both tails, however only</tt> </tt>
<a name="L443"></a><tt class="py-lineno">443</tt>  <tt class="py-line">        <tt class="py-comment"># negative values may lead to numerical issues -- $e^{-a}$</tt> </tt>
<a name="L444"></a><tt class="py-lineno">444</tt>  <tt class="py-line">        <tt class="py-comment"># clip() function does the following operation faster:</tt> </tt>
<a name="L445"></a><tt class="py-lineno">445</tt>  <tt class="py-line">        <tt class="py-comment"># a[a &lt; -30.] = -30,</tt> </tt>
<a name="L446"></a><tt class="py-lineno">446</tt>  <tt class="py-line">        <tt class="py-comment"># a[a &gt; 30.] = 30.</tt> </tt>
<a name="L447"></a><tt class="py-lineno">447</tt>  <tt class="py-line">        <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">clip</tt><tt class="py-op">(</tt><tt class="py-name">a</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">30.0</tt><tt class="py-op">,</tt> <tt class="py-number">30.0</tt><tt class="py-op">,</tt> <tt class="py-name">out</tt><tt class="py-op">=</tt><tt class="py-name">a</tt><tt class="py-op">)</tt> </tt>
<a name="L448"></a><tt class="py-lineno">448</tt>  <tt class="py-line">        <tt class="py-name">h</tt> <tt class="py-op">=</tt> <tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-op">(</tt><tt class="py-number">1</tt> <tt class="py-op">+</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-name">a</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L449"></a><tt class="py-lineno">449</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">h</tt> </tt>
</div><a name="L450"></a><tt class="py-lineno">450</tt>  <tt class="py-line"> </tt>
<a name="Sigmoid.bprop"></a><div id="Sigmoid.bprop-def"><a name="L451"></a><tt class="py-lineno">451</tt> <a class="py-toggle" href="#" id="Sigmoid.bprop-toggle" onclick="return toggle('Sigmoid.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Sigmoid-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Sigmoid.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Sigmoid.bprop-expanded"><a name="L452"></a><tt class="py-lineno">452</tt>  <tt class="py-line"> </tt>
<a name="L453"></a><tt class="py-lineno">453</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt><tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L454"></a><tt class="py-lineno">454</tt>  <tt class="py-line">            <tt class="py-name">igrads</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L455"></a><tt class="py-lineno">455</tt>  <tt class="py-line">        <tt class="py-name">dsigm</tt> <tt class="py-op">=</tt> <tt class="py-name">h</tt> <tt class="py-op">*</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">-</tt> <tt class="py-name">h</tt><tt class="py-op">)</tt> </tt>
<a name="L456"></a><tt class="py-lineno">456</tt>  <tt class="py-line">        <tt class="py-name">deltas</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt> <tt class="py-op">*</tt> <tt class="py-name">dsigm</tt> </tt>
<a name="L457"></a><tt class="py-lineno">457</tt>  <tt class="py-line">        <tt class="py-name">___</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-47" class="py-name"><a title="mlp.layers.Sigmoid" class="py-name" href="#" onclick="return doclink('link-47', 'Sigmoid', 'link-43');">Sigmoid</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-48" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-48', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">=</tt><tt class="py-name">deltas</tt><tt class="py-op">)</tt> </tt>
<a name="L458"></a><tt class="py-lineno">458</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">deltas</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> </tt>
</div><a name="L459"></a><tt class="py-lineno">459</tt>  <tt class="py-line"> </tt>
<a name="Sigmoid.bprop_cost"></a><div id="Sigmoid.bprop_cost-def"><a name="L460"></a><tt class="py-lineno">460</tt> <a class="py-toggle" href="#" id="Sigmoid.bprop_cost-toggle" onclick="return toggle('Sigmoid.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Sigmoid-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Sigmoid.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Sigmoid.bprop_cost-expanded"><a name="L461"></a><tt class="py-lineno">461</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-49" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-49', 'cost', 'link-4');">cost</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt> <tt class="py-keyword">or</tt> <tt id="link-50" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-50', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-51" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-51', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">'bce'</tt> <tt class="py-keyword">or</tt> <tt class="py-name">True</tt><tt class="py-op">:</tt> </tt>
<a name="L462"></a><tt class="py-lineno">462</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-52" class="py-name"><a title="mlp.layers.Sigmoid" class="py-name" href="#" onclick="return doclink('link-52', 'Sigmoid', 'link-43');">Sigmoid</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-53" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-53', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">=</tt><tt class="py-name">h</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">=</tt><tt class="py-name">igrads</tt><tt class="py-op">)</tt> </tt>
<a name="L463"></a><tt class="py-lineno">463</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L464"></a><tt class="py-lineno">464</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Sigmoid.bprop_cost method not implemented '</tt> </tt>
<a name="L465"></a><tt class="py-lineno">465</tt>  <tt class="py-line">                                      <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-54" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-54', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-55" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-55', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L466"></a><tt class="py-lineno">466</tt>  <tt class="py-line"> </tt>
<a name="Sigmoid.get_name"></a><div id="Sigmoid.get_name-def"><a name="L467"></a><tt class="py-lineno">467</tt> <a class="py-toggle" href="#" id="Sigmoid.get_name-toggle" onclick="return toggle('Sigmoid.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Sigmoid-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Sigmoid.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Sigmoid.get_name-expanded"><a name="L468"></a><tt class="py-lineno">468</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'sigmoid'</tt> </tt>
</div></div><a name="L469"></a><tt class="py-lineno">469</tt>  <tt class="py-line"> </tt>
<a name="L470"></a><tt class="py-lineno">470</tt>  <tt class="py-line"> </tt>
<a name="Softmax"></a><div id="Softmax-def"><a name="L471"></a><tt class="py-lineno">471</tt> <a class="py-toggle" href="#" id="Softmax-toggle" onclick="return toggle('Softmax');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Softmax-class.html">Softmax</a><tt class="py-op">(</tt><tt class="py-base-class">Linear</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Softmax-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Softmax-expanded"><a name="L472"></a><tt class="py-lineno">472</tt>  <tt class="py-line"> </tt>
<a name="Softmax.__init__"></a><div id="Softmax.__init__-def"><a name="L473"></a><tt class="py-lineno">473</tt> <a class="py-toggle" href="#" id="Softmax.__init__-toggle" onclick="return toggle('Softmax.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Softmax-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L474"></a><tt class="py-lineno">474</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L475"></a><tt class="py-lineno">475</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Softmax.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Softmax.__init__-expanded"><a name="L476"></a><tt class="py-lineno">476</tt>  <tt class="py-line"> </tt>
<a name="L477"></a><tt class="py-lineno">477</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-56" class="py-name" targets="Class mlp.layers.Softmax=mlp.layers.Softmax-class.html"><a title="mlp.layers.Softmax" class="py-name" href="#" onclick="return doclink('link-56', 'Softmax', 'link-56');">Softmax</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-57" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-57', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> </tt>
<a name="L478"></a><tt class="py-lineno">478</tt>  <tt class="py-line">                                      <tt class="py-name">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L479"></a><tt class="py-lineno">479</tt>  <tt class="py-line">                                      <tt class="py-name">rng</tt><tt class="py-op">=</tt><tt class="py-name">rng</tt><tt class="py-op">,</tt> </tt>
<a name="L480"></a><tt class="py-lineno">480</tt>  <tt class="py-line">                                      <tt class="py-name">irange</tt><tt class="py-op">=</tt><tt class="py-name">irange</tt><tt class="py-op">)</tt> </tt>
</div><a name="L481"></a><tt class="py-lineno">481</tt>  <tt class="py-line"> </tt>
<a name="Softmax.fprop"></a><div id="Softmax.fprop-def"><a name="L482"></a><tt class="py-lineno">482</tt> <a class="py-toggle" href="#" id="Softmax.fprop-toggle" onclick="return toggle('Softmax.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Softmax-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Softmax.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Softmax.fprop-expanded"><a name="L483"></a><tt class="py-lineno">483</tt>  <tt class="py-line"> </tt>
<a name="L484"></a><tt class="py-lineno">484</tt>  <tt class="py-line">        <tt class="py-comment"># compute the linear outputs</tt> </tt>
<a name="L485"></a><tt class="py-lineno">485</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-58" class="py-name"><a title="mlp.layers.Softmax" class="py-name" href="#" onclick="return doclink('link-58', 'Softmax', 'link-56');">Softmax</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-59" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-59', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">)</tt> </tt>
<a name="L486"></a><tt class="py-lineno">486</tt>  <tt class="py-line">        <tt class="py-comment"># apply numerical stabilisation by subtracting max</tt> </tt>
<a name="L487"></a><tt class="py-lineno">487</tt>  <tt class="py-line">        <tt class="py-comment"># from each row (not required for the coursework)</tt> </tt>
<a name="L488"></a><tt class="py-lineno">488</tt>  <tt class="py-line">        <tt class="py-comment"># then compute exponent</tt> </tt>
<a name="L489"></a><tt class="py-lineno">489</tt>  <tt class="py-line">        <tt class="py-keyword">assert</tt> <tt class="py-name">a</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-keyword">in</tt> <tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt> </tt>
<a name="L490"></a><tt class="py-lineno">490</tt>  <tt class="py-line">            <tt class="py-string">"Expected the linear activation in Softmax layer to be either "</tt> </tt>
<a name="L491"></a><tt class="py-lineno">491</tt>  <tt class="py-line">            <tt class="py-string">"vector or matrix, got %ith dimensional tensor"</tt> <tt class="py-op">%</tt> <tt class="py-name">a</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> </tt>
<a name="L492"></a><tt class="py-lineno">492</tt>  <tt class="py-line">        <tt class="py-op">)</tt> </tt>
<a name="L493"></a><tt class="py-lineno">493</tt>  <tt class="py-line">        <tt class="py-name">axis</tt> <tt class="py-op">=</tt> <tt class="py-name">a</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">-</tt> <tt class="py-number">1</tt> </tt>
<a name="L494"></a><tt class="py-lineno">494</tt>  <tt class="py-line">        <tt class="py-name">exp_a</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-name">a</tt> <tt class="py-op">-</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">a</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-name">axis</tt><tt class="py-op">,</tt> <tt class="py-name">keepdims</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L495"></a><tt class="py-lineno">495</tt>  <tt class="py-line">        <tt class="py-comment"># finally, normalise by the sum within each example</tt> </tt>
<a name="L496"></a><tt class="py-lineno">496</tt>  <tt class="py-line">        <tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">exp_a</tt><tt class="py-op">/</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">exp_a</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-name">axis</tt><tt class="py-op">,</tt> <tt class="py-name">keepdims</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L497"></a><tt class="py-lineno">497</tt>  <tt class="py-line"> </tt>
<a name="L498"></a><tt class="py-lineno">498</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">y</tt> </tt>
</div><a name="L499"></a><tt class="py-lineno">499</tt>  <tt class="py-line"> </tt>
<a name="Softmax.bprop"></a><div id="Softmax.bprop-def"><a name="L500"></a><tt class="py-lineno">500</tt> <a class="py-toggle" href="#" id="Softmax.bprop-toggle" onclick="return toggle('Softmax.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Softmax-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Softmax.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Softmax.bprop-expanded"><a name="L501"></a><tt class="py-lineno">501</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt> </tt>
<a name="L502"></a><tt class="py-lineno">502</tt>  <tt class="py-line">            <tt class="py-string">'Softmax.bprop not implemented for hidden layer.'</tt><tt class="py-op">)</tt> </tt>
</div><a name="L503"></a><tt class="py-lineno">503</tt>  <tt class="py-line"> </tt>
<a name="Softmax.bprop_cost"></a><div id="Softmax.bprop_cost-def"><a name="L504"></a><tt class="py-lineno">504</tt> <a class="py-toggle" href="#" id="Softmax.bprop_cost-toggle" onclick="return toggle('Softmax.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Softmax-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Softmax.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Softmax.bprop_cost-expanded"><a name="L505"></a><tt class="py-lineno">505</tt>  <tt class="py-line"> </tt>
<a name="L506"></a><tt class="py-lineno">506</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-60" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-60', 'cost', 'link-4');">cost</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt> <tt class="py-keyword">or</tt> <tt id="link-61" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-61', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-62" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-62', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">'ce'</tt><tt class="py-op">:</tt> </tt>
<a name="L507"></a><tt class="py-lineno">507</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-63" class="py-name"><a title="mlp.layers.Softmax" class="py-name" href="#" onclick="return doclink('link-63', 'Softmax', 'link-56');">Softmax</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-64" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-64', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">=</tt><tt class="py-name">h</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">=</tt><tt class="py-name">igrads</tt><tt class="py-op">)</tt> </tt>
<a name="L508"></a><tt class="py-lineno">508</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L509"></a><tt class="py-lineno">509</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Softmax.bprop_cost method not implemented '</tt> </tt>
<a name="L510"></a><tt class="py-lineno">510</tt>  <tt class="py-line">                                      <tt class="py-string">'for %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-65" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-65', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-66" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-66', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L511"></a><tt class="py-lineno">511</tt>  <tt class="py-line"> </tt>
<a name="Softmax.get_name"></a><div id="Softmax.get_name-def"><a name="L512"></a><tt class="py-lineno">512</tt> <a class="py-toggle" href="#" id="Softmax.get_name-toggle" onclick="return toggle('Softmax.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Softmax-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Softmax.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Softmax.get_name-expanded"><a name="L513"></a><tt class="py-lineno">513</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'softmax'</tt> </tt>
</div></div><a name="L514"></a><tt class="py-lineno">514</tt>  <tt class="py-line"> </tt>
<a name="L515"></a><tt class="py-lineno">515</tt>  <tt class="py-line"> </tt>
<a name="Relu"></a><div id="Relu-def"><a name="L516"></a><tt class="py-lineno">516</tt> <a class="py-toggle" href="#" id="Relu-toggle" onclick="return toggle('Relu');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Relu-class.html">Relu</a><tt class="py-op">(</tt><tt class="py-base-class">Linear</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Relu-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Relu-expanded"><a name="L517"></a><tt class="py-lineno">517</tt>  <tt class="py-line"> </tt>
<a name="Relu.__init__"></a><div id="Relu.__init__-def"><a name="L518"></a><tt class="py-lineno">518</tt> <a class="py-toggle" href="#" id="Relu.__init__-toggle" onclick="return toggle('Relu.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Relu-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt>  <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L519"></a><tt class="py-lineno">519</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L520"></a><tt class="py-lineno">520</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Relu.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Relu.__init__-expanded"><a name="L521"></a><tt class="py-lineno">521</tt>  <tt class="py-line"> </tt>
<a name="L522"></a><tt class="py-lineno">522</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-67" class="py-name" targets="Class mlp.layers.Relu=mlp.layers.Relu-class.html"><a title="mlp.layers.Relu" class="py-name" href="#" onclick="return doclink('link-67', 'Relu', 'link-67');">Relu</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-68" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-68', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> <tt class="py-name">odim</tt><tt class="py-op">,</tt> <tt class="py-name">rng</tt><tt class="py-op">,</tt> <tt class="py-name">irange</tt><tt class="py-op">)</tt> </tt>
</div><a name="L523"></a><tt class="py-lineno">523</tt>  <tt class="py-line"> </tt>
<a name="Relu.fprop"></a><div id="Relu.fprop-def"><a name="L524"></a><tt class="py-lineno">524</tt> <a class="py-toggle" href="#" id="Relu.fprop-toggle" onclick="return toggle('Relu.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Relu-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Relu.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Relu.fprop-expanded"><a name="L525"></a><tt class="py-lineno">525</tt>  <tt class="py-line">        <tt class="py-comment"># get the linear activations</tt> </tt>
<a name="L526"></a><tt class="py-lineno">526</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-69" class="py-name"><a title="mlp.layers.Relu" class="py-name" href="#" onclick="return doclink('link-69', 'Relu', 'link-67');">Relu</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-70" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-70', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">)</tt> </tt>
<a name="L527"></a><tt class="py-lineno">527</tt>  <tt class="py-line">        <tt class="py-name">h</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">clip</tt><tt class="py-op">(</tt><tt class="py-name">a</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-number">20.0</tt><tt class="py-op">)</tt> </tt>
<a name="L528"></a><tt class="py-lineno">528</tt>  <tt class="py-line">        <tt class="py-comment">#h = numpy.maximum(a, 0)</tt> </tt>
<a name="L529"></a><tt class="py-lineno">529</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">h</tt> </tt>
</div><a name="L530"></a><tt class="py-lineno">530</tt>  <tt class="py-line"> </tt>
<a name="Relu.bprop"></a><div id="Relu.bprop-def"><a name="L531"></a><tt class="py-lineno">531</tt> <a class="py-toggle" href="#" id="Relu.bprop-toggle" onclick="return toggle('Relu.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Relu-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Relu.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Relu.bprop-expanded"><a name="L532"></a><tt class="py-lineno">532</tt>  <tt class="py-line">        <tt class="py-name">deltas</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-name">h</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">*</tt><tt class="py-name">igrads</tt> </tt>
<a name="L533"></a><tt class="py-lineno">533</tt>  <tt class="py-line">        <tt class="py-name">___</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-71" class="py-name"><a title="mlp.layers.Relu" class="py-name" href="#" onclick="return doclink('link-71', 'Relu', 'link-67');">Relu</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-72" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-72', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">=</tt><tt class="py-name">deltas</tt><tt class="py-op">)</tt> </tt>
<a name="L534"></a><tt class="py-lineno">534</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">deltas</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> </tt>
</div><a name="L535"></a><tt class="py-lineno">535</tt>  <tt class="py-line"> </tt>
<a name="Relu.bprop_cost"></a><div id="Relu.bprop_cost-def"><a name="L536"></a><tt class="py-lineno">536</tt> <a class="py-toggle" href="#" id="Relu.bprop_cost-toggle" onclick="return toggle('Relu.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Relu-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Relu.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Relu.bprop_cost-expanded"><a name="L537"></a><tt class="py-lineno">537</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Relu.bprop_cost method not implemented '</tt> </tt>
<a name="L538"></a><tt class="py-lineno">538</tt>  <tt class="py-line">                                  <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-73" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-73', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-74" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-74', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L539"></a><tt class="py-lineno">539</tt>  <tt class="py-line"> </tt>
<a name="Relu.get_name"></a><div id="Relu.get_name-def"><a name="L540"></a><tt class="py-lineno">540</tt> <a class="py-toggle" href="#" id="Relu.get_name-toggle" onclick="return toggle('Relu.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Relu-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Relu.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Relu.get_name-expanded"><a name="L541"></a><tt class="py-lineno">541</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'relu'</tt> </tt>
</div></div><a name="L542"></a><tt class="py-lineno">542</tt>  <tt class="py-line"> </tt>
<a name="L543"></a><tt class="py-lineno">543</tt>  <tt class="py-line"> </tt>
<a name="Tanh"></a><div id="Tanh-def"><a name="L544"></a><tt class="py-lineno">544</tt> <a class="py-toggle" href="#" id="Tanh-toggle" onclick="return toggle('Tanh');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Tanh-class.html">Tanh</a><tt class="py-op">(</tt><tt class="py-base-class">Linear</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tanh-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Tanh-expanded"><a name="L545"></a><tt class="py-lineno">545</tt>  <tt class="py-line"> </tt>
<a name="Tanh.__init__"></a><div id="Tanh.__init__-def"><a name="L546"></a><tt class="py-lineno">546</tt> <a class="py-toggle" href="#" id="Tanh.__init__-toggle" onclick="return toggle('Tanh.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Tanh-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt>  <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L547"></a><tt class="py-lineno">547</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L548"></a><tt class="py-lineno">548</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tanh.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tanh.__init__-expanded"><a name="L549"></a><tt class="py-lineno">549</tt>  <tt class="py-line"> </tt>
<a name="L550"></a><tt class="py-lineno">550</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-75" class="py-name" targets="Class mlp.layers.Tanh=mlp.layers.Tanh-class.html"><a title="mlp.layers.Tanh" class="py-name" href="#" onclick="return doclink('link-75', 'Tanh', 'link-75');">Tanh</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-76" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-76', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> <tt class="py-name">odim</tt><tt class="py-op">,</tt> <tt class="py-name">rng</tt><tt class="py-op">,</tt> <tt class="py-name">irange</tt><tt class="py-op">)</tt> </tt>
</div><a name="L551"></a><tt class="py-lineno">551</tt>  <tt class="py-line"> </tt>
<a name="Tanh.fprop"></a><div id="Tanh.fprop-def"><a name="L552"></a><tt class="py-lineno">552</tt> <a class="py-toggle" href="#" id="Tanh.fprop-toggle" onclick="return toggle('Tanh.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Tanh-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tanh.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tanh.fprop-expanded"><a name="L553"></a><tt class="py-lineno">553</tt>  <tt class="py-line">        <tt class="py-comment"># get the linear activations</tt> </tt>
<a name="L554"></a><tt class="py-lineno">554</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-77" class="py-name"><a title="mlp.layers.Tanh" class="py-name" href="#" onclick="return doclink('link-77', 'Tanh', 'link-75');">Tanh</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-78" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-78', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">)</tt> </tt>
<a name="L555"></a><tt class="py-lineno">555</tt>  <tt class="py-line">        <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">clip</tt><tt class="py-op">(</tt><tt class="py-name">a</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">30.0</tt><tt class="py-op">,</tt> <tt class="py-number">30.0</tt><tt class="py-op">,</tt> <tt class="py-name">out</tt><tt class="py-op">=</tt><tt class="py-name">a</tt><tt class="py-op">)</tt> </tt>
<a name="L556"></a><tt class="py-lineno">556</tt>  <tt class="py-line">        <tt class="py-name">h</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">tanh</tt><tt class="py-op">(</tt><tt class="py-name">a</tt><tt class="py-op">)</tt> </tt>
<a name="L557"></a><tt class="py-lineno">557</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">h</tt> </tt>
</div><a name="L558"></a><tt class="py-lineno">558</tt>  <tt class="py-line"> </tt>
<a name="Tanh.bprop"></a><div id="Tanh.bprop-def"><a name="L559"></a><tt class="py-lineno">559</tt> <a class="py-toggle" href="#" id="Tanh.bprop-toggle" onclick="return toggle('Tanh.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Tanh-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tanh.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tanh.bprop-expanded"><a name="L560"></a><tt class="py-lineno">560</tt>  <tt class="py-line">        <tt class="py-name">deltas</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">-</tt> <tt class="py-name">h</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">igrads</tt> </tt>
<a name="L561"></a><tt class="py-lineno">561</tt>  <tt class="py-line">        <tt class="py-name">___</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-79" class="py-name"><a title="mlp.layers.Tanh" class="py-name" href="#" onclick="return doclink('link-79', 'Tanh', 'link-75');">Tanh</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-80" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-80', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">=</tt><tt class="py-name">deltas</tt><tt class="py-op">)</tt> </tt>
<a name="L562"></a><tt class="py-lineno">562</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">deltas</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> </tt>
</div><a name="L563"></a><tt class="py-lineno">563</tt>  <tt class="py-line"> </tt>
<a name="Tanh.bprop_cost"></a><div id="Tanh.bprop_cost-def"><a name="L564"></a><tt class="py-lineno">564</tt> <a class="py-toggle" href="#" id="Tanh.bprop_cost-toggle" onclick="return toggle('Tanh.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Tanh-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tanh.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tanh.bprop_cost-expanded"><a name="L565"></a><tt class="py-lineno">565</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Tanh.bprop_cost method not implemented '</tt> </tt>
<a name="L566"></a><tt class="py-lineno">566</tt>  <tt class="py-line">                                  <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-81" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-81', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-82" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-82', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L567"></a><tt class="py-lineno">567</tt>  <tt class="py-line"> </tt>
<a name="Tanh.get_name"></a><div id="Tanh.get_name-def"><a name="L568"></a><tt class="py-lineno">568</tt> <a class="py-toggle" href="#" id="Tanh.get_name-toggle" onclick="return toggle('Tanh.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Tanh-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tanh.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tanh.get_name-expanded"><a name="L569"></a><tt class="py-lineno">569</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'tanh'</tt> </tt>
</div></div><a name="L570"></a><tt class="py-lineno">570</tt>  <tt class="py-line"> </tt>
<a name="L571"></a><tt class="py-lineno">571</tt>  <tt class="py-line"> </tt>
<a name="Maxout"></a><div id="Maxout-def"><a name="L572"></a><tt class="py-lineno">572</tt> <a class="py-toggle" href="#" id="Maxout-toggle" onclick="return toggle('Maxout');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.Maxout-class.html">Maxout</a><tt class="py-op">(</tt><tt class="py-base-class">Linear</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Maxout-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Maxout-expanded"><a name="L573"></a><tt class="py-lineno">573</tt>  <tt class="py-line"> </tt>
<a name="Maxout.__init__"></a><div id="Maxout.__init__-def"><a name="L574"></a><tt class="py-lineno">574</tt> <a class="py-toggle" href="#" id="Maxout.__init__-toggle" onclick="return toggle('Maxout.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Maxout-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt>  <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> <tt class="py-param">k</tt><tt class="py-op">,</tt> </tt>
<a name="L575"></a><tt class="py-lineno">575</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L576"></a><tt class="py-lineno">576</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.05</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Maxout.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Maxout.__init__-expanded"><a name="L577"></a><tt class="py-lineno">577</tt>  <tt class="py-line"> </tt>
<a name="L578"></a><tt class="py-lineno">578</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-83" class="py-name" targets="Class mlp.layers.Maxout=mlp.layers.Maxout-class.html"><a title="mlp.layers.Maxout" class="py-name" href="#" onclick="return doclink('link-83', 'Maxout', 'link-83');">Maxout</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-84" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-84', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> <tt class="py-name">odim</tt><tt class="py-op">*</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">rng</tt><tt class="py-op">,</tt> <tt class="py-name">irange</tt><tt class="py-op">)</tt> </tt>
<a name="L579"></a><tt class="py-lineno">579</tt>  <tt class="py-line"> </tt>
<a name="L580"></a><tt class="py-lineno">580</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">max_odim</tt> <tt class="py-op">=</tt> <tt class="py-name">odim</tt> </tt>
<a name="L581"></a><tt class="py-lineno">581</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">=</tt> <tt class="py-name">k</tt> </tt>
</div><a name="L582"></a><tt class="py-lineno">582</tt>  <tt class="py-line"> </tt>
<a name="Maxout.fprop"></a><div id="Maxout.fprop-def"><a name="L583"></a><tt class="py-lineno">583</tt> <a class="py-toggle" href="#" id="Maxout.fprop-toggle" onclick="return toggle('Maxout.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Maxout-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Maxout.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Maxout.fprop-expanded"><a name="L584"></a><tt class="py-lineno">584</tt>  <tt class="py-line">        <tt class="py-comment"># get the linear activations</tt> </tt>
<a name="L585"></a><tt class="py-lineno">585</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-85" class="py-name"><a title="mlp.layers.Maxout" class="py-name" href="#" onclick="return doclink('link-85', 'Maxout', 'link-83');">Maxout</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-86" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.fprop
mlp.convlin.ConvMaxPool2D.fprop
mlp.convlin.ConvRelu_Opt.fprop
mlp.convlin.ConvSigmoid_Opt.fprop
mlp.layers.ComplexAbs.fprop
mlp.layers.ComplexLinear.fprop
mlp.layers.Layer.fprop
mlp.layers.Linear.fprop
mlp.layers.MLP.fprop
mlp.layers.Maxout.fprop
mlp.layers.Relu.fprop
mlp.layers.Sigmoid.fprop
mlp.layers.Softmax.fprop
mlp.layers.Tanh.fprop" class="py-name" href="#" onclick="return doclink('link-86', 'fprop', 'link-14');">fprop</a></tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">)</tt> </tt>
<a name="L586"></a><tt class="py-lineno">586</tt>  <tt class="py-line">        <tt class="py-name">ar</tt> <tt class="py-op">=</tt> <tt class="py-name">a</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">a</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">max_odim</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt><tt class="py-op">)</tt> </tt>
<a name="L587"></a><tt class="py-lineno">587</tt>  <tt class="py-line">        <tt class="py-name">h</tt><tt class="py-op">,</tt> <tt class="py-name">h_argmax</tt> <tt class="py-op">=</tt> <tt id="link-87" class="py-name" targets="Function mlp.layers.max_and_argmax()=mlp.layers-module.html#max_and_argmax"><a title="mlp.layers.max_and_argmax" class="py-name" href="#" onclick="return doclink('link-87', 'max_and_argmax', 'link-87');">max_and_argmax</a></tt><tt class="py-op">(</tt> </tt>
<a name="L588"></a><tt class="py-lineno">588</tt>  <tt class="py-line">            <tt class="py-name">ar</tt><tt class="py-op">,</tt> <tt class="py-name">axes</tt><tt class="py-op">=</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">keepdims_max</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">,</tt> <tt class="py-name">keepdims_argmax</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L589"></a><tt class="py-lineno">589</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">h_argmax</tt> <tt class="py-op">=</tt> <tt class="py-name">h_argmax</tt> </tt>
<a name="L590"></a><tt class="py-lineno">590</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">h</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt><tt class="py-op">]</tt>  <tt class="py-comment"># get rid of the last reduced dimensison (of size 1)</tt> </tt>
</div><a name="L591"></a><tt class="py-lineno">591</tt>  <tt class="py-line"> </tt>
<a name="Maxout.bprop"></a><div id="Maxout.bprop-def"><a name="L592"></a><tt class="py-lineno">592</tt> <a class="py-toggle" href="#" id="Maxout.bprop-toggle" onclick="return toggle('Maxout.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Maxout-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Maxout.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Maxout.bprop-expanded"><a name="L593"></a><tt class="py-lineno">593</tt>  <tt class="py-line">        <tt class="py-comment"># hack for dropout backprop (ignore dropped neurons). Note, this is not</tt> </tt>
<a name="L594"></a><tt class="py-lineno">594</tt>  <tt class="py-line">        <tt class="py-comment"># entirely correct when h fires at 0 exaclty (but is not dropped, in which case</tt> </tt>
<a name="L595"></a><tt class="py-lineno">595</tt>  <tt class="py-line">        <tt class="py-comment"># derivative should be 1). However, this is rather unlikely to happen (that h fires as 0)</tt> </tt>
<a name="L596"></a><tt class="py-lineno">596</tt>  <tt class="py-line">        <tt class="py-comment"># and probably can be ignored for now. Otherwise, one would have to keep the dropped unit</tt> </tt>
<a name="L597"></a><tt class="py-lineno">597</tt>  <tt class="py-line">        <tt class="py-comment"># indexes and zero grads according to them.</tt> </tt>
<a name="L598"></a><tt class="py-lineno">598</tt>  <tt class="py-line">        <tt class="py-name">igrads</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-name">h</tt> <tt class="py-op">!=</tt> <tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">*</tt><tt class="py-name">igrads</tt> </tt>
<a name="L599"></a><tt class="py-lineno">599</tt>  <tt class="py-line">        <tt class="py-comment"># convert into the shape where upsampling is easier</tt> </tt>
<a name="L600"></a><tt class="py-lineno">600</tt>  <tt class="py-line">        <tt class="py-name">igrads_up</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">max_odim</tt><tt class="py-op">,</tt> <tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L601"></a><tt class="py-lineno">601</tt>  <tt class="py-line">        <tt class="py-comment"># upsample to the linear dimension (but reshaped to (batch_size,</tt> </tt>
<a name="L602"></a><tt class="py-lineno">602</tt>  <tt class="py-line">        <tt class="py-comment"># maxed_num (1), pool_size)</tt> </tt>
<a name="L603"></a><tt class="py-lineno">603</tt>  <tt class="py-line">        <tt class="py-name">igrads_up</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">tile</tt><tt class="py-op">(</tt><tt class="py-name">igrads_up</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L604"></a><tt class="py-lineno">604</tt>  <tt class="py-line">        <tt class="py-comment"># generate mask matrix and set to 1 maxed elements</tt> </tt>
<a name="L605"></a><tt class="py-lineno">605</tt>  <tt class="py-line">        <tt class="py-name">mask</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">zeros_like</tt><tt class="py-op">(</tt><tt class="py-name">igrads_up</tt><tt class="py-op">)</tt> </tt>
<a name="L606"></a><tt class="py-lineno">606</tt>  <tt class="py-line">        <tt class="py-name">mask</tt><tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">h_argmax</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-number">1.0</tt> </tt>
<a name="L607"></a><tt class="py-lineno">607</tt>  <tt class="py-line">        <tt class="py-comment"># do bprop through max operator and then reshape into 2D</tt> </tt>
<a name="L608"></a><tt class="py-lineno">608</tt>  <tt class="py-line">        <tt class="py-name">deltas</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-name">igrads_up</tt> <tt class="py-op">*</tt> <tt class="py-name">mask</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">igrads_up</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L609"></a><tt class="py-lineno">609</tt>  <tt class="py-line">        <tt class="py-comment"># and then do bprop thorough linear part</tt> </tt>
<a name="L610"></a><tt class="py-lineno">610</tt>  <tt class="py-line">        <tt class="py-name">___</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-88" class="py-name"><a title="mlp.layers.Maxout" class="py-name" href="#" onclick="return doclink('link-88', 'Maxout', 'link-83');">Maxout</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-89" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-89', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">=</tt><tt class="py-name">deltas</tt><tt class="py-op">)</tt> </tt>
<a name="L611"></a><tt class="py-lineno">611</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">deltas</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> </tt>
</div><a name="L612"></a><tt class="py-lineno">612</tt>  <tt class="py-line"> </tt>
<a name="Maxout.bprop_cost"></a><div id="Maxout.bprop_cost-def"><a name="L613"></a><tt class="py-lineno">613</tt> <a class="py-toggle" href="#" id="Maxout.bprop_cost-toggle" onclick="return toggle('Maxout.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Maxout-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Maxout.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Maxout.bprop_cost-expanded"><a name="L614"></a><tt class="py-lineno">614</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Maxout.bprop_cost method not implemented '</tt> </tt>
<a name="L615"></a><tt class="py-lineno">615</tt>  <tt class="py-line">                                  <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-90" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-90', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-91" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-91', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L616"></a><tt class="py-lineno">616</tt>  <tt class="py-line"> </tt>
<a name="Maxout.get_name"></a><div id="Maxout.get_name-def"><a name="L617"></a><tt class="py-lineno">617</tt> <a class="py-toggle" href="#" id="Maxout.get_name-toggle" onclick="return toggle('Maxout.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.Maxout-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Maxout.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Maxout.get_name-expanded"><a name="L618"></a><tt class="py-lineno">618</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'maxout'</tt> </tt>
</div></div><a name="L619"></a><tt class="py-lineno">619</tt>  <tt class="py-line"> </tt>
<a name="L620"></a><tt class="py-lineno">620</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear"></a><div id="ComplexLinear-def"><a name="L621"></a><tt class="py-lineno">621</tt> <a class="py-toggle" href="#" id="ComplexLinear-toggle" onclick="return toggle('ComplexLinear');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html">ComplexLinear</a><tt class="py-op">(</tt><tt class="py-base-class">Layer</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="ComplexLinear-expanded"><a name="L622"></a><tt class="py-lineno">622</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L623"></a><tt class="py-lineno">623</tt>  <tt class="py-line"><tt class="py-docstring">    This layer sets up the two weight matrices required for the ADFT layer</tt> </tt>
<a name="L624"></a><tt class="py-lineno">624</tt>  <tt class="py-line"><tt class="py-docstring">    implemented as compelx abs</tt> </tt>
<a name="L625"></a><tt class="py-lineno">625</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L626"></a><tt class="py-lineno">626</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.__init__"></a><div id="ComplexLinear.__init__-def"><a name="L627"></a><tt class="py-lineno">627</tt> <a class="py-toggle" href="#" id="ComplexLinear.__init__-toggle" onclick="return toggle('ComplexLinear.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L628"></a><tt class="py-lineno">628</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L629"></a><tt class="py-lineno">629</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.__init__-expanded"><a name="L630"></a><tt class="py-lineno">630</tt>  <tt class="py-line"> </tt>
<a name="L631"></a><tt class="py-lineno">631</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-92" class="py-name" targets="Class mlp.layers.ComplexLinear=mlp.layers.ComplexLinear-class.html"><a title="mlp.layers.ComplexLinear" class="py-name" href="#" onclick="return doclink('link-92', 'ComplexLinear', 'link-92');">ComplexLinear</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-93" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-93', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">rng</tt><tt class="py-op">=</tt><tt class="py-name">rng</tt><tt class="py-op">)</tt> </tt>
<a name="L632"></a><tt class="py-lineno">632</tt>  <tt class="py-line"> </tt>
<a name="L633"></a><tt class="py-lineno">633</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">idim</tt> <tt class="py-op">=</tt> <tt class="py-name">idim</tt> </tt>
<a name="L634"></a><tt class="py-lineno">634</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">odim</tt> <tt class="py-op">=</tt> <tt class="py-name">odim</tt> </tt>
<a name="L635"></a><tt class="py-lineno">635</tt>  <tt class="py-line">        <tt class="py-comment"># must be true for fourier layer</tt> </tt>
<a name="L636"></a><tt class="py-lineno">636</tt>  <tt class="py-line">        <tt class="py-keyword">assert</tt> <tt class="py-name">idim</tt> <tt class="py-op">==</tt> <tt class="py-name">odim</tt> </tt>
<a name="L637"></a><tt class="py-lineno">637</tt>  <tt class="py-line"> </tt>
<a name="L638"></a><tt class="py-lineno">638</tt>  <tt class="py-line">        <tt class="py-comment"># odim  is output and the input dimensions of the DFT layer</tt> </tt>
<a name="L639"></a><tt class="py-lineno">639</tt>  <tt class="py-line">        <tt class="py-name">dft_mat</tt> <tt class="py-op">=</tt> <tt class="py-name">dft</tt><tt class="py-op">(</tt><tt class="py-name">odim</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">T</tt> </tt>
<a name="L640"></a><tt class="py-lineno">640</tt>  <tt class="py-line">        <tt class="py-comment"># diag(M * M^{dagger}) gives me the normalization values for each row</tt> </tt>
<a name="L641"></a><tt class="py-lineno">641</tt>  <tt class="py-line">        <tt class="py-comment"># setting M = M^T does the trick for collumns</tt> </tt>
<a name="L642"></a><tt class="py-lineno">642</tt>  <tt class="py-line">        <tt class="py-name">normalization_vals</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">diag</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">dft_mat</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">conj</tt><tt class="py-op">(</tt><tt class="py-name">dft_mat</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L643"></a><tt class="py-lineno">643</tt>  <tt class="py-line">        <tt class="py-comment"># This is the renormalized weight matrix from my understanding</tt> </tt>
<a name="L644"></a><tt class="py-lineno">644</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt> <tt class="py-op">=</tt> <tt class="py-name">dft_mat</tt>  <tt class="py-comment"># / normalization_vals.reshape(-1,1)</tt> </tt>
<a name="L645"></a><tt class="py-lineno">645</tt>  <tt class="py-line">        <tt class="py-comment"># seperating in to two (outputing double number of neurons )</tt> </tt>
<a name="L646"></a><tt class="py-lineno">646</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">real</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt><tt class="py-op">)</tt> </tt>
<a name="L647"></a><tt class="py-lineno">647</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">imag</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">W</tt><tt class="py-op">)</tt> </tt>
<a name="L648"></a><tt class="py-lineno">648</tt>  <tt class="py-line"> </tt>
<a name="L649"></a><tt class="py-lineno">649</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">zeros</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">odim</tt><tt class="py-op">*</tt><tt class="py-number">2</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">dtype</tt><tt class="py-op">=</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">float32</tt><tt class="py-op">)</tt> </tt>
</div><a name="L650"></a><tt class="py-lineno">650</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.norm_weights"></a><div id="ComplexLinear.norm_weights-def"><a name="L651"></a><tt class="py-lineno">651</tt> <a class="py-toggle" href="#" id="ComplexLinear.norm_weights-toggle" onclick="return toggle('ComplexLinear.norm_weights');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#norm_weights">norm_weights</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">train_iterator</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.norm_weights-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.norm_weights-expanded"><a name="L652"></a><tt class="py-lineno">652</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L653"></a><tt class="py-lineno">653</tt>  <tt class="py-line"><tt class="py-docstring">        Normalize dft weights by $E[(wx)^2]$</tt> </tt>
<a name="L654"></a><tt class="py-lineno">654</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L655"></a><tt class="py-lineno">655</tt>  <tt class="py-line">        <tt class="py-name">n</tt> <tt class="py-op">=</tt> <tt class="py-number">1</tt> </tt>
<a name="L656"></a><tt class="py-lineno">656</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">t</tt> <tt class="py-keyword">in</tt> <tt class="py-name">train_iterator</tt><tt class="py-op">:</tt> </tt>
<a name="L657"></a><tt class="py-lineno">657</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">n</tt> <tt class="py-op">==</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L658"></a><tt class="py-lineno">658</tt>  <tt class="py-line">                <tt class="py-comment"># + self.b</tt> </tt>
<a name="L659"></a><tt class="py-lineno">659</tt>  <tt class="py-line">                <tt class="py-name">n1</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">*</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt> </tt>
<a name="L660"></a><tt class="py-lineno">660</tt>  <tt class="py-line">                <tt class="py-name">n2</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">*</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt> </tt>
<a name="L661"></a><tt class="py-lineno">661</tt>  <tt class="py-line">                <tt class="py-name">n</tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L662"></a><tt class="py-lineno">662</tt>  <tt class="py-line">                <tt class="py-keyword">continue</tt> </tt>
<a name="L663"></a><tt class="py-lineno">663</tt>  <tt class="py-line">            <tt class="py-name">n1</tt> <tt class="py-op">+=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> \ </tt>
<a name="L664"></a><tt class="py-lineno">664</tt>  <tt class="py-line">                <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt>  <tt class="py-comment"># + self.b</tt> </tt>
<a name="L665"></a><tt class="py-lineno">665</tt>  <tt class="py-line">            <tt class="py-name">n2</tt> <tt class="py-op">+=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt><tt class="py-op">/</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">*</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt> </tt>
<a name="L666"></a><tt class="py-lineno">666</tt>  <tt class="py-line">            <tt class="py-name">n</tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L667"></a><tt class="py-lineno">667</tt>  <tt class="py-line">        <tt class="py-name">n1</tt> <tt class="py-op">/=</tt> <tt class="py-name">n</tt> </tt>
<a name="L668"></a><tt class="py-lineno">668</tt>  <tt class="py-line">        <tt class="py-name">n2</tt> <tt class="py-op">/=</tt> <tt class="py-name">n</tt> </tt>
<a name="L669"></a><tt class="py-lineno">669</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt> <tt class="py-op">/</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">(</tt><tt class="py-name">n1</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt> </tt>
<a name="L670"></a><tt class="py-lineno">670</tt>  <tt class="py-line">        <tt class="py-name">n2m</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">(</tt><tt class="py-name">n2</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt> </tt>
<a name="L671"></a><tt class="py-lineno">671</tt>  <tt class="py-line">        <tt class="py-name">n2m</tt><tt class="py-op">[</tt><tt class="py-name">n2m</tt> <tt class="py-op">==</tt> <tt class="py-number">0.0</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-number">1.0</tt> </tt>
<a name="L672"></a><tt class="py-lineno">672</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt> <tt class="py-op">/</tt> <tt class="py-name">n2m</tt> </tt>
</div><a name="L673"></a><tt class="py-lineno">673</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.fprop"></a><div id="ComplexLinear.fprop-def"><a name="L674"></a><tt class="py-lineno">674</tt> <a class="py-toggle" href="#" id="ComplexLinear.fprop-toggle" onclick="return toggle('ComplexLinear.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.fprop-expanded"><a name="L675"></a><tt class="py-lineno">675</tt>  <tt class="py-line"> </tt>
<a name="L676"></a><tt class="py-lineno">676</tt>  <tt class="py-line">        <tt class="py-comment"># input comes from 4D convolutional tensor, reshape to expected shape</tt> </tt>
<a name="L677"></a><tt class="py-lineno">677</tt>  <tt class="py-line">        <tt class="py-comment"># a_old = numpy.dot(inputs, self.W)</tt> </tt>
<a name="L678"></a><tt class="py-lineno">678</tt>  <tt class="py-line"> </tt>
<a name="L679"></a><tt class="py-lineno">679</tt>  <tt class="py-line">        <tt class="py-name">a1</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">)</tt>  <tt class="py-comment"># + self.b</tt> </tt>
<a name="L680"></a><tt class="py-lineno">680</tt>  <tt class="py-line">        <tt class="py-name">a2</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">)</tt>  <tt class="py-comment"># + self.b</tt> </tt>
<a name="L681"></a><tt class="py-lineno">681</tt>  <tt class="py-line">        <tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">concatenate</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">a1</tt><tt class="py-op">,</tt> <tt class="py-name">a2</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L682"></a><tt class="py-lineno">682</tt>  <tt class="py-line">        <tt class="py-comment"># a = a_old + self.b</tt> </tt>
<a name="L683"></a><tt class="py-lineno">683</tt>  <tt class="py-line">        <tt class="py-comment"># here f() is an identity function, so just return a linear</tt> </tt>
<a name="L684"></a><tt class="py-lineno">684</tt>  <tt class="py-line">        <tt class="py-comment"># transformation</tt> </tt>
<a name="L685"></a><tt class="py-lineno">685</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">a</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> </tt>
</div><a name="L686"></a><tt class="py-lineno">686</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.bprop"></a><div id="ComplexLinear.bprop-def"><a name="L687"></a><tt class="py-lineno">687</tt> <a class="py-toggle" href="#" id="ComplexLinear.bprop-toggle" onclick="return toggle('ComplexLinear.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.bprop-expanded"><a name="L688"></a><tt class="py-lineno">688</tt>  <tt class="py-line">        <tt class="py-comment"># self.first = False</tt> </tt>
<a name="L689"></a><tt class="py-lineno">689</tt>  <tt class="py-line">        <tt class="py-comment"># since df^i/da^i = 1 (f is assumed identity function),</tt> </tt>
<a name="L690"></a><tt class="py-lineno">690</tt>  <tt class="py-line">        <tt class="py-comment"># deltas are in fact the same as igrads</tt> </tt>
<a name="L691"></a><tt class="py-lineno">691</tt>  <tt class="py-line">        <tt class="py-name">igrads</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">,</tt> </tt>
<a name="L692"></a><tt class="py-lineno">692</tt>  <tt class="py-line">                                <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-op">/</tt> <tt class="py-number">2</tt><tt class="py-op">)</tt> </tt>
<a name="L693"></a><tt class="py-lineno">693</tt>  <tt class="py-line">        <tt class="py-name">ir</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">:</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt> </tt>
<a name="L694"></a><tt class="py-lineno">694</tt>  <tt class="py-line">        <tt class="py-name">ii</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">:</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt> </tt>
<a name="L695"></a><tt class="py-lineno">695</tt>  <tt class="py-line">        <tt class="py-name">ograds</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">concatenate</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">ir</tt><tt class="py-op">,</tt> <tt class="py-name">ii</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L696"></a><tt class="py-lineno">696</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">igrads</tt><tt class="py-op">,</tt> <tt class="py-name">ograds</tt> </tt>
</div><a name="L697"></a><tt class="py-lineno">697</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.bprop_cost"></a><div id="ComplexLinear.bprop_cost-def"><a name="L698"></a><tt class="py-lineno">698</tt> <a class="py-toggle" href="#" id="ComplexLinear.bprop_cost-toggle" onclick="return toggle('ComplexLinear.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.bprop_cost-expanded"><a name="L699"></a><tt class="py-lineno">699</tt>  <tt class="py-line"> </tt>
<a name="L700"></a><tt class="py-lineno">700</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-94" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-94', 'cost', 'link-4');">cost</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt> <tt class="py-keyword">or</tt> <tt id="link-95" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-95', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-96" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-96', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">'mse'</tt><tt class="py-op">:</tt> </tt>
<a name="L701"></a><tt class="py-lineno">701</tt>  <tt class="py-line">            <tt class="py-comment"># for linear layer and mean square error cost,</tt> </tt>
<a name="L702"></a><tt class="py-lineno">702</tt>  <tt class="py-line">            <tt class="py-comment"># cost back-prop is the same as standard back-prop</tt> </tt>
<a name="L703"></a><tt class="py-lineno">703</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-97" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.bprop
mlp.convlin.ConvMaxPool2D.bprop
mlp.convlin.ConvRelu_Opt.bprop
mlp.convlin.ConvSigmoid_Opt.bprop
mlp.layers.ComplexAbs.bprop
mlp.layers.ComplexLinear.bprop
mlp.layers.Layer.bprop
mlp.layers.Linear.bprop
mlp.layers.MLP.bprop
mlp.layers.Maxout.bprop
mlp.layers.Relu.bprop
mlp.layers.Sigmoid.bprop
mlp.layers.Softmax.bprop
mlp.layers.Tanh.bprop" class="py-name" href="#" onclick="return doclink('link-97', 'bprop', 'link-30');">bprop</a></tt><tt class="py-op">(</tt><tt class="py-name">h</tt><tt class="py-op">,</tt> <tt class="py-name">igrads</tt><tt class="py-op">)</tt> </tt>
<a name="L704"></a><tt class="py-lineno">704</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L705"></a><tt class="py-lineno">705</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Linear.bprop_cost method not implemented '</tt> </tt>
<a name="L706"></a><tt class="py-lineno">706</tt>  <tt class="py-line">                                      <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-98" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-98', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-99" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-99', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L707"></a><tt class="py-lineno">707</tt>  <tt class="py-line"> </tt>
<a name="L708"></a><tt class="py-lineno">708</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.get_params"></a><div id="ComplexLinear.get_params-def"><a name="L709"></a><tt class="py-lineno">709</tt> <a class="py-toggle" href="#" id="ComplexLinear.get_params-toggle" onclick="return toggle('ComplexLinear.get_params');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#get_params">get_params</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.get_params-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.get_params-expanded"><a name="L710"></a><tt class="py-lineno">710</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt><tt class="py-op">]</tt> </tt>
</div><a name="L711"></a><tt class="py-lineno">711</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.set_params"></a><div id="ComplexLinear.set_params-def"><a name="L712"></a><tt class="py-lineno">712</tt> <a class="py-toggle" href="#" id="ComplexLinear.set_params-toggle" onclick="return toggle('ComplexLinear.set_params');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#set_params">set_params</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">params</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.set_params-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.set_params-expanded"><a name="L713"></a><tt class="py-lineno">713</tt>  <tt class="py-line">        <tt class="py-comment"># we do not make checks here, but the order on the list</tt> </tt>
<a name="L714"></a><tt class="py-lineno">714</tt>  <tt class="py-line">        <tt class="py-comment"># is assumed to be exactly the same as get_params() returns</tt> </tt>
<a name="L715"></a><tt class="py-lineno">715</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt> <tt class="py-op">=</tt> <tt class="py-name">params</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> </tt>
<a name="L716"></a><tt class="py-lineno">716</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt> <tt class="py-op">=</tt> <tt class="py-name">params</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
<a name="L717"></a><tt class="py-lineno">717</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">b</tt> <tt class="py-op">=</tt> <tt class="py-name">params</tt><tt class="py-op">[</tt><tt class="py-number">2</tt><tt class="py-op">]</tt> </tt>
</div><a name="L718"></a><tt class="py-lineno">718</tt>  <tt class="py-line"> </tt>
<a name="ComplexLinear.get_name"></a><div id="ComplexLinear.get_name-def"><a name="L719"></a><tt class="py-lineno">719</tt> <a class="py-toggle" href="#" id="ComplexLinear.get_name-toggle" onclick="return toggle('ComplexLinear.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexLinear-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexLinear.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexLinear.get_name-expanded"><a name="L720"></a><tt class="py-lineno">720</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'clinear'</tt> </tt>
</div></div><a name="L721"></a><tt class="py-lineno">721</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs"></a><div id="ComplexAbs-def"><a name="L722"></a><tt class="py-lineno">722</tt> <a class="py-toggle" href="#" id="ComplexAbs-toggle" onclick="return toggle('ComplexAbs');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html">ComplexAbs</a><tt class="py-op">(</tt><tt class="py-base-class">ComplexLinear</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="ComplexAbs-expanded"><a name="L723"></a><tt class="py-lineno">723</tt>  <tt class="py-line"> </tt>
<a name="L724"></a><tt class="py-lineno">724</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L725"></a><tt class="py-lineno">725</tt>  <tt class="py-line"><tt class="py-docstring">    Implements an ADFT (Spectral layer) with $|a|^{2}$ based</tt> </tt>
<a name="L726"></a><tt class="py-lineno">726</tt>  <tt class="py-line"><tt class="py-docstring">    activation functions.</tt> </tt>
<a name="L727"></a><tt class="py-lineno">727</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L728"></a><tt class="py-lineno">728</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs.__init__"></a><div id="ComplexAbs.__init__-def"><a name="L729"></a><tt class="py-lineno">729</tt> <a class="py-toggle" href="#" id="ComplexAbs.__init__-toggle" onclick="return toggle('ComplexAbs.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt>  <tt class="py-param">idim</tt><tt class="py-op">,</tt> <tt class="py-param">odim</tt><tt class="py-op">,</tt> </tt>
<a name="L730"></a><tt class="py-lineno">730</tt>  <tt class="py-line">                 <tt class="py-param">rng</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> </tt>
<a name="L731"></a><tt class="py-lineno">731</tt>  <tt class="py-line">                 <tt class="py-param">irange</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexAbs.__init__-expanded"><a name="L732"></a><tt class="py-lineno">732</tt>  <tt class="py-line"> </tt>
<a name="L733"></a><tt class="py-lineno">733</tt>  <tt class="py-line">        <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-100" class="py-name" targets="Class mlp.layers.ComplexAbs=mlp.layers.ComplexAbs-class.html"><a title="mlp.layers.ComplexAbs" class="py-name" href="#" onclick="return doclink('link-100', 'ComplexAbs', 'link-100');">ComplexAbs</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-101" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.__init__
mlp.convlin.ConvMaxPool2D.__init__
mlp.convlin.ConvRelu_Opt.__init__
mlp.convlin.ConvSigmoid_Opt.__init__
mlp.dataset.DataProvider.__init__
mlp.dataset.FuncDataProvider.__init__
mlp.dataset.MACLDataProvider.__init__
mlp.dataset.MetOfficeDataProvider.__init__
mlp.dataset.mACLEnum.__init__
mlp.layers.ComplexAbs.__init__
mlp.layers.ComplexLinear.__init__
mlp.layers.Layer.__init__
mlp.layers.Linear.__init__
mlp.layers.MLP.__init__
mlp.layers.Maxout.__init__
mlp.layers.Relu.__init__
mlp.layers.Sigmoid.__init__
mlp.layers.Softmax.__init__
mlp.layers.Tanh.__init__
mlp.optimisers.SGDOptimiser.__init__
mlp.schedulers.DropoutFixed.__init__
mlp.schedulers.LearningRateFixed.__init__
mlp.schedulers.LearningRateList.__init__
mlp.schedulers.LearningRateNewBob.__init__
mlp.schedulers.LearningRateScheduler.__init__" class="py-name" href="#" onclick="return doclink('link-101', '__init__', 'link-36');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">idim</tt><tt class="py-op">,</tt> <tt class="py-name">odim</tt><tt class="py-op">,</tt> <tt class="py-name">rng</tt><tt class="py-op">,</tt> <tt class="py-name">irange</tt><tt class="py-op">)</tt> </tt>
</div><a name="L734"></a><tt class="py-lineno">734</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs.fprop"></a><div id="ComplexAbs.fprop-def"><a name="L735"></a><tt class="py-lineno">735</tt> <a class="py-toggle" href="#" id="ComplexAbs.fprop-toggle" onclick="return toggle('ComplexAbs.fprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html#fprop">fprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs.fprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexAbs.fprop-expanded"><a name="L736"></a><tt class="py-lineno">736</tt>  <tt class="py-line"> </tt>
<a name="L737"></a><tt class="py-lineno">737</tt>  <tt class="py-line">        <tt class="py-comment"># input comes from 4D convolutional tensor, reshape to expected shape</tt> </tt>
<a name="L738"></a><tt class="py-lineno">738</tt>  <tt class="py-line"> </tt>
<a name="L739"></a><tt class="py-lineno">739</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L740"></a><tt class="py-lineno">740</tt>  <tt class="py-line">            <tt class="py-name">inputs</tt> <tt class="py-op">=</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L741"></a><tt class="py-lineno">741</tt>  <tt class="py-line"> </tt>
<a name="L742"></a><tt class="py-lineno">742</tt>  <tt class="py-line">        <tt class="py-name">a1</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">power</tt><tt class="py-op">(</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">)</tt>  <tt class="py-comment"># + self.b</tt> </tt>
<a name="L743"></a><tt class="py-lineno">743</tt>  <tt class="py-line">        <tt class="py-name">a2</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">power</tt><tt class="py-op">(</tt><tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">)</tt>  <tt class="py-comment"># + self.b</tt> </tt>
<a name="L744"></a><tt class="py-lineno">744</tt>  <tt class="py-line"> </tt>
<a name="L745"></a><tt class="py-lineno">745</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">sqrt</tt><tt class="py-op">(</tt><tt class="py-name">a1</tt> <tt class="py-op">+</tt> <tt class="py-name">a2</tt><tt class="py-op">)</tt> </tt>
</div><a name="L746"></a><tt class="py-lineno">746</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs.bprop"></a><div id="ComplexAbs.bprop-def"><a name="L747"></a><tt class="py-lineno">747</tt> <a class="py-toggle" href="#" id="ComplexAbs.bprop-toggle" onclick="return toggle('ComplexAbs.bprop');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html#bprop">bprop</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs.bprop-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexAbs.bprop-expanded"><a name="L748"></a><tt class="py-lineno">748</tt>  <tt class="py-line"> </tt>
<a name="L749"></a><tt class="py-lineno">749</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt><tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L750"></a><tt class="py-lineno">750</tt>  <tt class="py-line">            <tt class="py-name">igrads</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L751"></a><tt class="py-lineno">751</tt>  <tt class="py-line"> </tt>
<a name="L752"></a><tt class="py-lineno">752</tt>  <tt class="py-line">        <tt class="py-comment"># Derivative of $h(a)= \sqrt{a}$ is $h(a)^{-1}$</tt> </tt>
<a name="L753"></a><tt class="py-lineno">753</tt>  <tt class="py-line">        <tt class="py-name">igrads</tt> <tt class="py-op">=</tt> <tt class="py-name">igrads</tt> <tt class="py-op">/</tt> <tt class="py-name">h</tt> </tt>
<a name="L754"></a><tt class="py-lineno">754</tt>  <tt class="py-line"> </tt>
<a name="L755"></a><tt class="py-lineno">755</tt>  <tt class="py-line">        <tt class="py-comment"># for backpropagating to next layer (ograds)</tt> </tt>
<a name="L756"></a><tt class="py-lineno">756</tt>  <tt class="py-line">        <tt class="py-name">ir</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt> </tt>
<a name="L757"></a><tt class="py-lineno">757</tt>  <tt class="py-line">        <tt class="py-name">ii</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">igrads</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">)</tt> </tt>
<a name="L758"></a><tt class="py-lineno">758</tt>  <tt class="py-line"> </tt>
<a name="L759"></a><tt class="py-lineno">759</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">igrads</tt><tt class="py-op">,</tt> <tt class="py-name">ir</tt> <tt class="py-op">+</tt> <tt class="py-name">ii</tt> </tt>
</div><a name="L760"></a><tt class="py-lineno">760</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs.bprop_cost"></a><div id="ComplexAbs.bprop_cost-def"><a name="L761"></a><tt class="py-lineno">761</tt> <a class="py-toggle" href="#" id="ComplexAbs.bprop_cost-toggle" onclick="return toggle('ComplexAbs.bprop_cost');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html#bprop_cost">bprop_cost</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">h</tt><tt class="py-op">,</tt> <tt class="py-param">igrads</tt><tt class="py-op">,</tt> <tt class="py-param">cost</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs.bprop_cost-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexAbs.bprop_cost-expanded"><a name="L762"></a><tt class="py-lineno">762</tt>  <tt class="py-line"> </tt>
<a name="L763"></a><tt class="py-lineno">763</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">NotImplementedError</tt><tt class="py-op">(</tt><tt class="py-string">'Sigmoid.bprop_cost method not implemented '</tt> </tt>
<a name="L764"></a><tt class="py-lineno">764</tt>  <tt class="py-line">                                  <tt class="py-string">'for the %s cost'</tt> <tt class="py-op">%</tt> <tt id="link-102" class="py-name"><a title="mlp.costs.CECost.cost
mlp.costs.Cost.cost
mlp.costs.MSECost.cost" class="py-name" href="#" onclick="return doclink('link-102', 'cost', 'link-4');">cost</a></tt><tt class="py-op">.</tt><tt id="link-103" class="py-name"><a title="mlp.convlin.ConvLinear_Opt.get_name
mlp.convlin.ConvMaxPool2D.get_name
mlp.convlin.ConvRelu_Opt.get_name
mlp.convlin.ConvSigmoid_Opt.get_name
mlp.costs.CECost.get_name
mlp.costs.Cost.get_name
mlp.costs.MSECost.get_name
mlp.layers.ComplexAbs.get_name
mlp.layers.ComplexLinear.get_name
mlp.layers.Layer.get_name
mlp.layers.Linear.get_name
mlp.layers.MLP.get_name
mlp.layers.Maxout.get_name
mlp.layers.Relu.get_name
mlp.layers.Sigmoid.get_name
mlp.layers.Softmax.get_name
mlp.layers.Tanh.get_name" class="py-name" href="#" onclick="return doclink('link-103', 'get_name', 'link-39');">get_name</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L765"></a><tt class="py-lineno">765</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs.pgrads"></a><div id="ComplexAbs.pgrads-def"><a name="L766"></a><tt class="py-lineno">766</tt> <a class="py-toggle" href="#" id="ComplexAbs.pgrads-toggle" onclick="return toggle('ComplexAbs.pgrads');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html#pgrads">pgrads</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">inputs</tt><tt class="py-op">,</tt> <tt class="py-param">deltas</tt><tt class="py-op">,</tt> </tt>
<a name="L767"></a><tt class="py-lineno">767</tt>  <tt class="py-line">               <tt class="py-param">l1_weight</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-param">l2_weight</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs.pgrads-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexAbs.pgrads-expanded"><a name="L768"></a><tt class="py-lineno">768</tt>  <tt class="py-line"> </tt>
<a name="L769"></a><tt class="py-lineno">769</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">ndim</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">2</tt><tt class="py-op">:</tt> </tt>
<a name="L770"></a><tt class="py-lineno">770</tt>  <tt class="py-line">            <tt class="py-name">inputs</tt> <tt class="py-op">=</tt> <tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L771"></a><tt class="py-lineno">771</tt>  <tt class="py-line"> </tt>
<a name="L772"></a><tt class="py-lineno">772</tt>  <tt class="py-line">        <tt class="py-name">grad_Wr</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">,</tt> </tt>
<a name="L773"></a><tt class="py-lineno">773</tt>  <tt class="py-line">                            <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wr</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">deltas</tt><tt class="py-op">)</tt> </tt>
<a name="L774"></a><tt class="py-lineno">774</tt>  <tt class="py-line">        <tt class="py-name">grad_Wi</tt> <tt class="py-op">=</tt> <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">,</tt> </tt>
<a name="L775"></a><tt class="py-lineno">775</tt>  <tt class="py-line">                            <tt class="py-name">numpy</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">inputs</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">Wi</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">deltas</tt><tt class="py-op">)</tt> </tt>
<a name="L776"></a><tt class="py-lineno">776</tt>  <tt class="py-line"> </tt>
<a name="L777"></a><tt class="py-lineno">777</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">[</tt><tt class="py-name">grad_Wr</tt><tt class="py-op">,</tt> <tt class="py-name">grad_Wi</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt><tt class="py-op">]</tt> </tt>
</div><a name="L778"></a><tt class="py-lineno">778</tt>  <tt class="py-line"> </tt>
<a name="L779"></a><tt class="py-lineno">779</tt>  <tt class="py-line"> </tt>
<a name="ComplexAbs.get_name"></a><div id="ComplexAbs.get_name-def"><a name="L780"></a><tt class="py-lineno">780</tt> <a class="py-toggle" href="#" id="ComplexAbs.get_name-toggle" onclick="return toggle('ComplexAbs.get_name');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="mlp.layers.ComplexAbs-class.html#get_name">get_name</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ComplexAbs.get_name-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="ComplexAbs.get_name-expanded"><a name="L781"></a><tt class="py-lineno">781</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">'abs'</tt> </tt>
</div></div><a name="L782"></a><tt class="py-lineno">782</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="mlp-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Tue Mar 29 01:41:00 2016
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
