{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday Meeting \n",
    "\n",
    "\n",
    "I have adapted the MLP dataprovider to the accelerometer data set to be used. I found the NN coded by Pawel extremely well documented and useful and thus I have picked it over Lasagne, tensorflow or the horrendous scikit learn (on which I wasted a whole day pointlessly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import logging\n",
    "from mlp.dataset import *\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "train_dp = ACLDataProvider(dset='train', batch_size=100, max_num_batches=-10, randomize=True)\n",
    "valid_dp = ACLDataProvider(dset='valid', batch_size=1824, max_num_batches=1, randomize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 3.127. Accuracy is 7.35%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 3.155. Accuracy is 7.35%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.607. Accuracy is 40.89%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 1.636. Accuracy is 54.06%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 1.376. Accuracy is 60.32%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 1.084. Accuracy is 64.58%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 1.041. Accuracy is 68.35%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 1.047. Accuracy is 68.09%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.876. Accuracy is 72.56%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 1.053. Accuracy is 66.17%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.819. Accuracy is 73.62%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.849. Accuracy is 72.70%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.701. Accuracy is 77.58%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.764. Accuracy is 75.00%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.598. Accuracy is 80.50%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.677. Accuracy is 76.86%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.572. Accuracy is 81.26%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.697. Accuracy is 77.74%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 0 seconds. Training speed 51436 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.552. Accuracy is 82.93%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.718. Accuracy is 76.81%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.486. Accuracy is 84.68%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.680. Accuracy is 77.08%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 0 seconds. Training speed 42359 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.448. Accuracy is 85.50%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.610. Accuracy is 79.82%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.431. Accuracy is 85.99%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.816. Accuracy is 73.68%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 0 seconds. Training speed 40006 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.422. Accuracy is 86.56%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.569. Accuracy is 80.65%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.367. Accuracy is 88.60%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.717. Accuracy is 79.06%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.344. Accuracy is 89.44%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.521. Accuracy is 82.79%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.341. Accuracy is 89.57%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.537. Accuracy is 81.96%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.305. Accuracy is 90.43%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.555. Accuracy is 81.14%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 0 seconds. Training speed 45006 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.294. Accuracy is 91.36%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.566. Accuracy is 80.54%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 0 seconds. Training speed 42359 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.280. Accuracy is 91.44%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.491. Accuracy is 83.55%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.267. Accuracy is 92.21%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.592. Accuracy is 81.91%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.242. Accuracy is 93.11%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.490. Accuracy is 83.55%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.236. Accuracy is 93.35%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.490. Accuracy is 83.50%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.237. Accuracy is 93.10%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.518. Accuracy is 82.46%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 0 seconds. Training speed 40006 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.224. Accuracy is 93.53%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.482. Accuracy is 84.05%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 0 seconds. Training speed 40006 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.218. Accuracy is 94.04%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.480. Accuracy is 83.44%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.202. Accuracy is 94.51%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.471. Accuracy is 83.94%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.188. Accuracy is 95.17%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.475. Accuracy is 83.61%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.187. Accuracy is 95.06%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.458. Accuracy is 83.72%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 0 seconds. Training speed 51436 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.172. Accuracy is 95.68%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.463. Accuracy is 84.59%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 0 seconds. Training speed 48007 pps. Validation speed 91250 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.164. Accuracy is 95.96%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.465. Accuracy is 84.59%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 0 seconds. Training speed 45006 pps. Validation speed 91250 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 84.59 %, cost (ce) is 0.465\n"
     ]
    }
   ],
   "source": [
    "#Baseline experiment\n",
    "from copy import deepcopy\n",
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 100\n",
    "learning_rate = 0.5\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "    \n",
    "stats = list()\n",
    "\n",
    "test_dp = deepcopy(valid_dp)\n",
    "train_dp.reset()\n",
    "valid_dp.reset()\n",
    "test_dp.reset()\n",
    "\n",
    "#define the model\n",
    "model = MLP(cost=cost)\n",
    "model.add_layer(Sigmoid(idim=125, odim=125*2, irange=1.6, rng=rng))\n",
    "model.add_layer(Softmax(idim=125*2, odim=19, rng=rng))\n",
    "\n",
    "# define the optimiser, here stochasitc gradient descent\n",
    "# with fixed learning rate and max_epochs\n",
    "lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "optimiser = SGDOptimiser(lr_scheduler=lr_scheduler)\n",
    "\n",
    "logger.info('Training started...')\n",
    "tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "logger.info('Testing the model on test set:')\n",
    "\n",
    "tst_cost, tst_accuracy = optimiser.validate(model,test_dp )\n",
    "logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import logging\n",
    "from mlp.dataset import *\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "train_dp = ACLDataProvider(dset='train', batch_size=100, max_num_batches=-10, randomize=True)\n",
    "valid_dp = ACLDataProvider(dset='valid', batch_size=1824, max_num_batches=1, randomize=False)\n",
    "\n",
    "\n",
    "#Baseline experiment\n",
    "from copy import deepcopy\n",
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.layers import * \n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 100\n",
    "learning_rate = 0.5\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "    \n",
    "stats = list()\n",
    "\n",
    "test_dp = deepcopy(valid_dp)\n",
    "train_dp.reset()\n",
    "valid_dp.reset()\n",
    "test_dp.reset()\n",
    "\n",
    "#define the model\n",
    "model = MLP(cost=cost)\n",
    "model.add_layer(ComplexLinear(idim=125, odim=125, irange=1.6, rng=rng))\n",
    "model.add_layer(Sigmoid(idim=125, odim=125, irange=1.6, rng=rng))\n",
    "model.add_layer(Softmax(idim=125, odim=19, rng=rng))\n",
    "\n",
    "# define the optimiser, here stochasitc gradient descent\n",
    "# with fixed learning rate and max_epochs\n",
    "lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "optimiser = SGDOptimiser(lr_scheduler=lr_scheduler)\n",
    "\n",
    "logger.info('Training started...')\n",
    "tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "logger.info('Testing the model on test set:')\n",
    "\n",
    "tst_cost, tst_accuracy = optimiser.validate(model,test_dp )\n",
    "logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7296, 500) (7296,)\n",
      "(7296, 125)\n",
      "(1824, 500)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 3.121. Accuracy is 3.18%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 3.105. Accuracy is 3.40%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.175. Accuracy is 37.57%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 1.748. Accuracy is 48.74%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 0 seconds. Training speed 30004 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 1.581. Accuracy is 54.57%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 1.473. Accuracy is 57.46%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 1.373. Accuracy is 60.47%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 1.340. Accuracy is 60.42%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 1.250. Accuracy is 64.51%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 1.233. Accuracy is 63.76%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 1.160. Accuracy is 66.69%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 1.171. Accuracy is 66.56%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 1.092. Accuracy is 69.00%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 1.112. Accuracy is 67.43%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 1.042. Accuracy is 70.22%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.071. Accuracy is 69.19%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.988. Accuracy is 71.76%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.042. Accuracy is 68.70%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.954. Accuracy is 73.32%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 1.010. Accuracy is 69.85%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 0 seconds. Training speed 30004 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.922. Accuracy is 73.75%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.980. Accuracy is 71.33%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.891. Accuracy is 74.42%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.955. Accuracy is 71.71%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.866. Accuracy is 74.94%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.939. Accuracy is 71.33%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.842. Accuracy is 75.61%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.923. Accuracy is 71.82%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.820. Accuracy is 76.43%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.902. Accuracy is 73.19%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 0 seconds. Training speed 30004 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.803. Accuracy is 76.88%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.895. Accuracy is 72.26%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 0 seconds. Training speed 30004 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.790. Accuracy is 77.36%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.877. Accuracy is 72.64%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.769. Accuracy is 78.19%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.871. Accuracy is 73.46%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.754. Accuracy is 78.32%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.855. Accuracy is 72.86%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.743. Accuracy is 78.69%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.851. Accuracy is 74.07%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 0 seconds. Training speed 30004 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.731. Accuracy is 79.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.843. Accuracy is 73.36%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 0 seconds. Training speed 21821 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.720. Accuracy is 79.17%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.840. Accuracy is 72.92%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 0 seconds. Training speed 26670 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.706. Accuracy is 79.54%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.832. Accuracy is 73.79%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 0 seconds. Training speed 26670 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.691. Accuracy is 80.29%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.819. Accuracy is 73.74%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 0 seconds. Training speed 26670 pps. Validation speed 36500 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.681. Accuracy is 80.21%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.824. Accuracy is 73.30%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 0 seconds. Training speed 28804 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.673. Accuracy is 80.78%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.808. Accuracy is 74.73%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 0 seconds. Training speed 30004 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.666. Accuracy is 80.94%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.815. Accuracy is 73.36%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 0 seconds. Training speed 31309 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.654. Accuracy is 81.35%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.794. Accuracy is 74.40%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.643. Accuracy is 81.72%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.794. Accuracy is 75.22%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 0 seconds. Training speed 26670 pps. Validation speed 45625 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.640. Accuracy is 81.38%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.789. Accuracy is 74.62%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 0 seconds. Training speed 30004 pps. Validation speed 60833 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.627. Accuracy is 81.96%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.777. Accuracy is 75.22%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 0 seconds. Training speed 31309 pps. Validation speed 60833 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 75.22 %, cost (ce) is 0.777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1824,)\n",
      "(1824, 125)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import logging\n",
    "from mlp.dataset import *\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "train_dp = ACLDataProvider(dset='train', batch_size=100, max_num_batches=-10, randomize=True)\n",
    "valid_dp = ACLDataProvider(dset='valid', batch_size=1824, max_num_batches=1, randomize=False)\n",
    "\n",
    "\n",
    "#Baseline experiment\n",
    "from copy import deepcopy\n",
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.layers import * \n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 100\n",
    "learning_rate = 0.07\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "    \n",
    "stats = list()\n",
    "\n",
    "test_dp = deepcopy(valid_dp)\n",
    "train_dp.reset()\n",
    "valid_dp.reset()\n",
    "test_dp.reset()\n",
    "\n",
    "\n",
    "#define the model\n",
    "model = MLP(cost=cost)\n",
    "model.add_layer(DFTLinear(idim=125, odim=125, irange=1.6, rng=rng))\n",
    "#Every activation function from dft layer produces two values (x,y) for x+iy\n",
    "model.add_layer(Sigmoid(idim=125*2, odim=125*2, irange=1.6, rng=rng))\n",
    "model.add_layer(Softmax(idim=125*2, odim=19, rng=rng))\n",
    "\n",
    "# define the optimiser, here stochasitc gradient descent\n",
    "# with fixed learning rate and max_epochs\n",
    "lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "optimiser = SGDOptimiser(lr_scheduler=lr_scheduler)\n",
    "\n",
    "logger.info('Training started...')\n",
    "tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "logger.info('Testing the model on test set:')\n",
    "\n",
    "tst_cost, tst_accuracy = optimiser.validate(model,test_dp )\n",
    "logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
